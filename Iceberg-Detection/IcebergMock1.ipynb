{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this competition, youâ€™re challenged to build an algorithm that automatically identifies if a remotely sensed target is a ship or iceberg. Improvements made will help drive the costs down for maintaining safe working conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import cv2\n",
    "import pdb\n",
    "import scipy\n",
    "import keras\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom, map_coordinates\n",
    "from scipy.ndimage import imread\n",
    "from scipy.ndimage import rotate as rot\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.signal import convolve2d\n",
    "from numpy.random import random_integers\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n",
    "                                 denoise_wavelet, estimate_sigma,\n",
    "                                 denoise_tv_bregman, denoise_nl_means)\n",
    "from skimage.filters import gaussian\n",
    "from skimage.color import rgb2gray\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation\n",
    "from keras.layers import GlobalMaxPooling2D, Lambda, Input, Flatten,LSTM\n",
    "from keras.layers import ZeroPadding2D, GlobalAveragePooling2D, Merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.models import Model, model_from_json, Sequential\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Adamax, Nadam, Adadelta, Adagrad\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau, History\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1 = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1 = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating the training bands\n",
    "# create 3 bands having HH, HV and avg of both\n",
    "X_band_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train_1[\"band_1\"]])\n",
    "X_band_2 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train_1[\"band_2\"]])\n",
    "X_train_1 = np.concatenate([X_band_1[:,:,:,np.newaxis], X_band_2[:,:,:,np.newaxis], ((X_band_1+X_band_2)/2)[:,:,:,np.newaxis]], axis =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel_1():\n",
    "    #Building the model\n",
    "    gmodel = Sequential()\n",
    "    \n",
    "    #Conv Layer 1\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.3))\n",
    "    \n",
    "    #Conv Layer 2\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
    "    gmodel.add(Dropout(0.3))\n",
    "    \n",
    "    #Conv Layer 3\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    gmodel.add(Dropout(0.3))\n",
    "    \n",
    "    #Conv Layer 4\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
    "    gmodel.add(Dropout(0.3))\n",
    "    \n",
    "    #Flatten the data for upcoming dense layers\n",
    "    gmodel.add(Flatten())\n",
    "    \n",
    "    #Dense Layer 1\n",
    "    gmodel.add(Dense(512))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "    \n",
    "    #Dense Layer 2\n",
    "    gmodel.add(Dense(256))\n",
    "    gmodel.add(Activation('selu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "    \n",
    "    #Sigmoid layer\n",
    "    gmodel.add(Dense(1))\n",
    "    gmodel.add(Activation('sigmoid'))\n",
    "    \n",
    "    #mypotim = Adam(lr=0.001, decay=0.0)#lr=0.001\n",
    "    mypotim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-06, decay=0.0)\n",
    "    \n",
    "    gmodel.compile(loss = 'binary_crossentropy',\n",
    "                   optimizer = mypotim,\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "    gmodel.summary()\n",
    "    return gmodel\n",
    "\n",
    "def get_callbacks(filepath):\n",
    "    es = EarlyStopping('val_loss', patience=10,mode='min')\n",
    "    msave = ModelCheckpoint(filepath,save_best_only = True)\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor = 0.1,\n",
    "                                  patience=7,\n",
    "                                  verbose = 0,\n",
    "                                  epsilon=1e-4,\n",
    "                                  mode='min')\n",
    "    return [es,msave, reduce_lr_loss]\n",
    "\n",
    "file_path = \".model_1_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train = train_1['is_iceberg']\n",
    "X_train_cv, X_valid, y_train_cv ,y_valid = train_test_split(X_train_1,\n",
    "                                                            target_train,\n",
    "                                                            random_state=1,\n",
    "                                                            train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#without denoising, core features\n",
    "model_1 = getModel_1()\n",
    "model_1.fit(X_train_cv,\n",
    "           y_train_cv,\n",
    "          batch_size =32,\n",
    "          epochs=125,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks= callbacks\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1.load_weights(filepath=file_path)\n",
    "score_1 = model_1.evaluate(X_valid, y_valid, verbose = 1)\n",
    "print('Train loss:', score_1[0])\n",
    "print('Train accuracy:', score_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in test_1[\"band_1\"]])\n",
    "X_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_1[\"band_2\"]])\n",
    "X_test_1 = np.concatenate([X_band_test_1[:, :, :, np.newaxis], \n",
    "                         X_band_test_2[:, :, :, np.newaxis],\n",
    "                         ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "predicted_test_1=model_1.predict_proba(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_1 = pd.DataFrame()\n",
    "submission_1['id']=test_1['id']\n",
    "submission_1['is_iceberg']=predicted_test_1.reshape((predicted_test_1.shape[0]))\n",
    "submission_1.to_csv('model_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_2 = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75,75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75,75)\n",
    "        band_3 = band_1 + band_2 \n",
    "        \n",
    "        #Rescale\n",
    "        a = (band_1 - band_1.mean())/(band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean())/(band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean())/(band_3.max() - band_3.min())\n",
    "        \n",
    "        imgs.append(np.dstack((a,b,c)))\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_2 = get_scaled_imgs(train_2)\n",
    "Ytrain_2 = np.array(train_2['is_iceberg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_2.inc_angle = train_2.inc_angle.replace('na',0)\n",
    "idx_tr = np.where(train_2.inc_angle>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrain_2 = Ytrain_2[idx_tr[0]]\n",
    "Xtrain_2 = Xtrain_2[idx_tr[0],...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_more_images(imgs):\n",
    "    more_images = []\n",
    "    vert_flip_imgs = []\n",
    "    hori_flip_imgs = []\n",
    "    \n",
    "    for i in range(0,imgs.shape[0]):\n",
    "        a = imgs[i,:,:,0]\n",
    "        b = imgs[i,:,:,1]\n",
    "        c = imgs[i,:,:,2]\n",
    "        \n",
    "        av = cv2.flip(a,1)\n",
    "        ah = cv2.flip(a,0)\n",
    "        bv = cv2.flip(b,1)\n",
    "        bh = cv2.flip(b,0)\n",
    "        cv = cv2.flip(c,1)\n",
    "        ch = cv2.flip(c,0)\n",
    "        \n",
    "        vert_flip_imgs.append(np.dstack((av,bv,cv)))\n",
    "        hori_flip_imgs.append(np.dstack((ah,bh,ch)))\n",
    "        \n",
    "    v = np.array(vert_flip_imgs)\n",
    "    h = np.array(hori_flip_imgs)\n",
    "    more_images = np.concatenate((imgs,v,h))\n",
    "    \n",
    "    return more_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr_more_1 = get_more_images(Xtrain_2) \n",
    "Ytr_more_1 = np.concatenate((Ytrain_2,Ytrain_2,Ytrain_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel_2():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # CNN 1\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 2\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 3\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #CNN 4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # You must flatten the data for the dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense 1\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Dense 2\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = Adam(lr=0.001, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = getModel_2()\n",
    "batch_size = 32\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss',\n",
    "                              patience =10,\n",
    "                              verbose = 0,\n",
    "                              mode = 'min'\n",
    "                             )\n",
    "mcp_save = ModelCheckpoint('.model_2_weights.hdf5',\n",
    "                           save_best_only=True,\n",
    "                           monitor = 'val_loss',\n",
    "                           mode = 'min'\n",
    "                          )\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor = 0.1,\n",
    "                                  patience=7,\n",
    "                                  verbose = 0,\n",
    "                                  epsilon=1e-4,\n",
    "                                  mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2.fit(Xtr_more_1,\n",
    "          Ytr_more_1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "         callbacks=[earlyStopping,mcp_save,reduce_lr_loss],\n",
    "                       validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2.load_weights(filepath = '.model_2_weights.hdf5')\n",
    "\n",
    "score_2 = model_2.evaluate(Xtrain_2, Ytrain_2, verbose=1)\n",
    "print('Train score:', score_2[0])\n",
    "print('Train accuracy:', score_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_2 = pd.read_json('test.json')\n",
    "test_2.inc_angle = test_2.inc_angle.replace('na',0)\n",
    "Xtest_2 = (get_scaled_imgs(test_2))\n",
    "pred_test_2 = model_2.predict(Xtest_2)\n",
    "\n",
    "submission_2 = pd.DataFrame({'id': test_2[\"id\"], 'is_iceberg': pred_test_2.reshape((pred_test_2.shape[0]))})\n",
    "submission_2.to_csv('model_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_3 = pd.read_json(\"train.json\")\n",
    "test_3 = pd.read_json(\"test.json\")\n",
    "train_3.inc_angle = train_3.inc_angle.replace('na',0)\n",
    "train_3.inc_angle = train_3.inc_angle.astype(float).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_3[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_3[\"band_2\"]])\n",
    "X_train_3 = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_train_3 = np.array(train_3.inc_angle)\n",
    "y_train_3 = np.array(train_3[\"is_iceberg\"])\n",
    "\n",
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_3[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_3[\"band_2\"]])\n",
    "X_test_3 = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_test_3 = np.array(test_3.inc_angle)\n",
    "\n",
    "\n",
    "X_train_3, X_valid_3, X_angle_train_3, X_angle_valid_3, y_train_3, y_valid_3 = train_test_split(\n",
    "    X_train_3, X_angle_train_3, y_train_3, random_state=123, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath):\n",
    "    es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor = 0.1,\n",
    "                                  patience=7,\n",
    "                                  verbose = 0,\n",
    "                                  epsilon=1e-4,\n",
    "                                  mode='min')\n",
    "    return [es, msave, reduce_lr_loss]\n",
    "    \n",
    "def get_model_3():\n",
    "    bn_model = 0\n",
    "    p_activation = \"elu\"\n",
    "    \n",
    "    input_1 = Input(shape=(75, 75, 3), name=\"X_1\")\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    \n",
    "    img_1 = Conv2D(16, kernel_size = (3,3), activation=p_activation) ((BatchNormalization(momentum=bn_model))(input_1))\n",
    "    img_1 = Conv2D(16, kernel_size = (3,3), activation=p_activation) (img_1)\n",
    "    img_1 = MaxPooling2D((2,2)) (img_1)\n",
    "    img_1 = Dropout(0.2)(img_1)\n",
    "    \n",
    "    img_1 = Conv2D(32, kernel_size = (3,3), activation=p_activation) (img_1)\n",
    "    img_1 = Conv2D(32, kernel_size = (3,3), activation=p_activation) (img_1)\n",
    "    img_1 = MaxPooling2D((2,2)) (img_1)\n",
    "    img_1 = Dropout(0.2)(img_1)\n",
    "    \n",
    "    img_1 = Conv2D(64, kernel_size = (3,3), activation=p_activation) (img_1)\n",
    "    img_1 = Conv2D(64, kernel_size = (3,3), activation=p_activation) (img_1)\n",
    "    img_1 = MaxPooling2D((2,2)) (img_1)\n",
    "    img_1 = Dropout(0.2)(img_1)\n",
    "    \n",
    "    img_1 = Conv2D(128, kernel_size = (3,3), activation=p_activation) (img_1)\n",
    "    img_1 = MaxPooling2D((2,2)) (img_1)\n",
    "    img_1 = Dropout(0.2)(img_1)\n",
    "    img_1 = GlobalMaxPooling2D() (img_1)\n",
    "    \n",
    "    img_2 = Conv2D(128, kernel_size = (3,3), activation=p_activation) ((BatchNormalization(momentum=bn_model))(input_1))\n",
    "    img_2 = MaxPooling2D((2,2)) (img_2)\n",
    "    img_2 = Dropout(0.2)(img_2)\n",
    "    img_2 = GlobalMaxPooling2D() (img_2)\n",
    "    \n",
    "    img_concat =  (Concatenate()([img_1, img_2, BatchNormalization(momentum=bn_model)(input_2)]))\n",
    "    \n",
    "    dense_ayer = Dropout(0.5) (BatchNormalization(momentum=bn_model) ( Dense(256, activation=p_activation)(img_concat) ))\n",
    "    dense_ayer = Dropout(0.5) (BatchNormalization(momentum=bn_model) ( Dense(64, activation=p_activation)(dense_ayer) ))\n",
    "    output = Dense(1, activation=\"sigmoid\")(dense_ayer)\n",
    "    \n",
    "    model = Model([input_1,input_2],  output)\n",
    "    #optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)#0.8728\n",
    "    optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=1e-06, decay=0.0)#0.8952\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1203 samples, validate on 401 samples\n",
      "Epoch 1/50\n",
      "1203/1203 [==============================] - 31s 26ms/step - loss: 0.8602 - acc: 0.5777 - val_loss: 0.8180 - val_acc: 0.5935\n",
      "Epoch 2/50\n",
      "1203/1203 [==============================] - 28s 23ms/step - loss: 0.7682 - acc: 0.5869 - val_loss: 0.6714 - val_acc: 0.5810\n",
      "Epoch 3/50\n",
      "1203/1203 [==============================] - 28s 23ms/step - loss: 0.6959 - acc: 0.5952 - val_loss: 1.2258 - val_acc: 0.5511\n",
      "Epoch 4/50\n",
      "1203/1203 [==============================] - 28s 24ms/step - loss: 0.6716 - acc: 0.6185 - val_loss: 0.6515 - val_acc: 0.5761\n",
      "Epoch 5/50\n",
      "1203/1203 [==============================] - 28s 24ms/step - loss: 0.6359 - acc: 0.6035 - val_loss: 1.1883 - val_acc: 0.5212\n",
      "Epoch 6/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.6857 - acc: 0.6293 - val_loss: 0.8726 - val_acc: 0.6010\n",
      "Epoch 7/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.6304 - acc: 0.6376 - val_loss: 0.6333 - val_acc: 0.6160\n",
      "Epoch 8/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.6568 - acc: 0.5993 - val_loss: 0.6919 - val_acc: 0.5810\n",
      "Epoch 9/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.6290 - acc: 0.6268 - val_loss: 0.6542 - val_acc: 0.6135\n",
      "Epoch 10/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.6156 - acc: 0.6409 - val_loss: 0.6603 - val_acc: 0.5985\n",
      "Epoch 11/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.6008 - acc: 0.6475 - val_loss: 4.0679 - val_acc: 0.5087\n",
      "Epoch 12/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.5751 - acc: 0.6675 - val_loss: 0.7159 - val_acc: 0.6334\n",
      "Epoch 13/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.5269 - acc: 0.7290 - val_loss: 0.5754 - val_acc: 0.6808\n",
      "Epoch 14/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.4584 - acc: 0.7689 - val_loss: 0.3632 - val_acc: 0.8304\n",
      "Epoch 15/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.3809 - acc: 0.8263 - val_loss: 0.4887 - val_acc: 0.7930\n",
      "Epoch 16/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.3437 - acc: 0.8512 - val_loss: 0.2783 - val_acc: 0.8853\n",
      "Epoch 17/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.3310 - acc: 0.8429 - val_loss: 0.5420 - val_acc: 0.7905\n",
      "Epoch 18/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.2950 - acc: 0.8670 - val_loss: 0.3638 - val_acc: 0.8603\n",
      "Epoch 19/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.3014 - acc: 0.8728 - val_loss: 0.3423 - val_acc: 0.8529\n",
      "Epoch 20/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.2717 - acc: 0.8786 - val_loss: 1.2188 - val_acc: 0.6658\n",
      "Epoch 21/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.2953 - acc: 0.8795 - val_loss: 0.3792 - val_acc: 0.8529\n",
      "Epoch 22/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.2515 - acc: 0.8936 - val_loss: 0.4771 - val_acc: 0.7880\n",
      "Epoch 23/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.2315 - acc: 0.9002 - val_loss: 0.4513 - val_acc: 0.8504\n",
      "Epoch 24/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.2394 - acc: 0.9027 - val_loss: 0.4239 - val_acc: 0.8728\n",
      "Epoch 25/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.1933 - acc: 0.9252 - val_loss: 0.2873 - val_acc: 0.8978\n",
      "Epoch 26/50\n",
      "1203/1203 [==============================] - 29s 24ms/step - loss: 0.1785 - acc: 0.9318 - val_loss: 0.3629 - val_acc: 0.8853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebe82efe10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \".model_3_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path)\n",
    "\n",
    "model_3 = get_model_3()\n",
    "model_3.fit([X_train_3,X_angle_train_3],\n",
    "          y_train_3,\n",
    "          epochs=50,\n",
    "          validation_data=([X_valid_3, X_angle_valid_3], y_valid_3),\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 3s 7ms/step\n",
      "Train score: 0.278252292675\n",
      "Train accuracy: 0.885286783042\n"
     ]
    }
   ],
   "source": [
    "model_3.load_weights(filepath=file_path)\n",
    "\n",
    "score_3 = (model_3.evaluate([X_valid_3, X_angle_valid_3], y_valid_3,verbose=1))\n",
    "\n",
    "print('Train score:', score_3[0])\n",
    "print('Train accuracy:', score_3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_3 = model_3.predict([X_test_3, X_angle_test_3],\n",
    "                             verbose=1,\n",
    "                             batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_3 = pd.DataFrame({'id': test_3[\"id\"], 'is_iceberg': prediction_3.reshape((prediction_3.shape[0]))})\n",
    "submission_3.to_csv(\"model_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_4 = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(df):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 / band_2\n",
    "\n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        images.append(rgb)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = get_images(train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = to_categorical(train_4.is_iceberg.values,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xv, ytr, yv = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(model, layers, filters):\n",
    "    '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_4():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input image: 75x75x3\n",
    "    model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "    ConvBlock(model, 1, 64)\n",
    "    # 37x37x32\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 18x18x64\n",
    "    ConvBlock(model, 1, 128)\n",
    "    # 9x9x128\n",
    "    ConvBlock(model, 1, 64)\n",
    "    # 4x4x128\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    # Output \n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4 = get_model_4()\n",
    "\n",
    "myoptimizer = Adam(lr=0.0001, decay=0.0)\n",
    "\n",
    "model_4.compile(loss='binary_crossentropy', optimizer=myoptimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_4 = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen_4.fit(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.6517 - acc: 0.6062 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.6064 - acc: 0.6508 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.5997 - acc: 0.6623 - val_loss: 0.6967 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 51s 1s/step - loss: 0.5861 - acc: 0.6695 - val_loss: 0.7008 - val_acc: 0.5358\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.5737 - acc: 0.6861 - val_loss: 0.7348 - val_acc: 0.5498\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.5684 - acc: 0.6851 - val_loss: 0.7109 - val_acc: 0.5125\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.5500 - acc: 0.7070 - val_loss: 0.7294 - val_acc: 0.5358\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.5361 - acc: 0.7090 - val_loss: 0.7521 - val_acc: 0.5405\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.5308 - acc: 0.7135 - val_loss: 0.7524 - val_acc: 0.5436\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.5297 - acc: 0.7288 - val_loss: 0.7550 - val_acc: 0.5748\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.5154 - acc: 0.7459 - val_loss: 0.6617 - val_acc: 0.6651\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.5076 - acc: 0.7526 - val_loss: 0.6354 - val_acc: 0.6745\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.5158 - acc: 0.7595 - val_loss: 0.6226 - val_acc: 0.6667\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.5139 - acc: 0.7551 - val_loss: 0.5722 - val_acc: 0.6978\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.5061 - acc: 0.7640 - val_loss: 0.5423 - val_acc: 0.7352\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 52s 1s/step - loss: 0.5080 - acc: 0.7726 - val_loss: 0.5328 - val_acc: 0.7664\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4990 - acc: 0.7849 - val_loss: 0.5100 - val_acc: 0.7960\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4978 - acc: 0.7861 - val_loss: 0.5231 - val_acc: 0.8162\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.4878 - acc: 0.7947 - val_loss: 0.5906 - val_acc: 0.7445\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4920 - acc: 0.7998 - val_loss: 0.5059 - val_acc: 0.8084\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4869 - acc: 0.8059 - val_loss: 0.5138 - val_acc: 0.7928\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.5007 - acc: 0.7852 - val_loss: 0.5152 - val_acc: 0.8053\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 56s 1s/step - loss: 0.4927 - acc: 0.7905 - val_loss: 0.4984 - val_acc: 0.8209\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4950 - acc: 0.8128 - val_loss: 0.5493 - val_acc: 0.7555\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4984 - acc: 0.7997 - val_loss: 0.5113 - val_acc: 0.8115\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.4887 - acc: 0.8048 - val_loss: 0.5195 - val_acc: 0.8084\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4811 - acc: 0.8187 - val_loss: 0.5356 - val_acc: 0.7648\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4762 - acc: 0.8225 - val_loss: 0.4962 - val_acc: 0.8162\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4906 - acc: 0.8039 - val_loss: 0.5068 - val_acc: 0.8224\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 56s 1s/step - loss: 0.4788 - acc: 0.8174 - val_loss: 0.5259 - val_acc: 0.7991\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 56s 1s/step - loss: 0.4903 - acc: 0.8083 - val_loss: 0.5077 - val_acc: 0.8115\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.4773 - acc: 0.8204 - val_loss: 0.5129 - val_acc: 0.7975\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4949 - acc: 0.7963 - val_loss: 0.4993 - val_acc: 0.8411\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4729 - acc: 0.8277 - val_loss: 0.5016 - val_acc: 0.8022\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4882 - acc: 0.8153 - val_loss: 0.5258 - val_acc: 0.7944\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4892 - acc: 0.8159 - val_loss: 0.5104 - val_acc: 0.7819\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4796 - acc: 0.8174 - val_loss: 0.5027 - val_acc: 0.8193\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4814 - acc: 0.8197 - val_loss: 0.5119 - val_acc: 0.8006\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.4711 - acc: 0.8347 - val_loss: 0.5235 - val_acc: 0.7866\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4712 - acc: 0.8325 - val_loss: 0.5013 - val_acc: 0.8022\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4733 - acc: 0.8237 - val_loss: 0.5262 - val_acc: 0.7944\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 56s 1s/step - loss: 0.4705 - acc: 0.8261 - val_loss: 0.4999 - val_acc: 0.8302\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4621 - acc: 0.8347 - val_loss: 0.5018 - val_acc: 0.8474\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.4672 - acc: 0.8363 - val_loss: 0.5040 - val_acc: 0.8240\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4781 - acc: 0.8294 - val_loss: 0.4905 - val_acc: 0.8442\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4627 - acc: 0.8421 - val_loss: 0.5003 - val_acc: 0.8567\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4686 - acc: 0.8416 - val_loss: 0.5068 - val_acc: 0.8505\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 56s 1s/step - loss: 0.4647 - acc: 0.8315 - val_loss: 0.5889 - val_acc: 0.7648\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4556 - acc: 0.8467 - val_loss: 0.4986 - val_acc: 0.8427\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.4636 - acc: 0.8433 - val_loss: 0.5044 - val_acc: 0.8318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264a6d54e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit_generator(datagen_4.flow(Xtr,\n",
    "                                     ytr,\n",
    "                                     batch_size=32),\n",
    "                      epochs=50,\n",
    "                      validation_data =(Xv, yv),\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4.save_weights('.model_4_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 5s 15ms/step\n",
      "Train score: 0.50441255952\n",
      "Train accuracy: 0.831775700935\n"
     ]
    }
   ],
   "source": [
    "score_4 = (model_4.evaluate(Xv,yv,verbose=1))\n",
    "\n",
    "print('Train score:', score_4[0])\n",
    "print('Train accuracy:', score_4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_4 = pd.read_json('test.json')\n",
    "Xtest_4 = get_images(test_4)\n",
    "test_predictions_4 = model_4.predict_proba(Xtest_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_4 = pd.DataFrame({'id': test_4['id'], 'is_iceberg': test_predictions_4[:, 1]})\n",
    "submission_4.to_csv('model_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MODEL 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_5 = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_5.inc_angle = train_5.inc_angle.map(lambda x: 0.0 if x == 'na' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform (df):\n",
    "    images = []\n",
    "    for i, row in df.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75,75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75,75)\n",
    "        band_3 = band_1 + band_2\n",
    "        \n",
    "        band_1_norm = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        band_2_norm = (band_2 - band_2. mean()) / (band_2.max() - band_2.min())\n",
    "        band_3_norm = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "        \n",
    "        images.append(np.dstack((band_1_norm, band_2_norm, band_3_norm)))\n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(images):\n",
    "    image_mirror_lr = []\n",
    "    image_mirror_ud = []\n",
    "    image_rotate = []\n",
    "    for i in range(0,images.shape[0]):\n",
    "        band_1 = images[i,:,:,0]\n",
    "        band_2 = images[i,:,:,1]\n",
    "        band_3 = images[i,:,:,2]\n",
    "            \n",
    "        # mirror left-right\n",
    "        band_1_mirror_lr = np.flip(band_1, 0)\n",
    "        band_2_mirror_lr = np.flip(band_2, 0)\n",
    "        band_3_mirror_lr = np.flip(band_3, 0)\n",
    "        image_mirror_lr.append(np.dstack((band_1_mirror_lr, band_2_mirror_lr, band_3_mirror_lr)))\n",
    "        \n",
    "        # mirror up-down\n",
    "        band_1_mirror_ud = np.flip(band_1, 1)\n",
    "        band_2_mirror_ud = np.flip(band_2, 1)\n",
    "        band_3_mirror_ud = np.flip(band_3, 1)\n",
    "        image_mirror_ud.append(np.dstack((band_1_mirror_ud, band_2_mirror_ud, band_3_mirror_ud)))\n",
    "        \n",
    "        #rotate \n",
    "        band_1_rotate = rot(band_1, 30, reshape=False)\n",
    "        band_2_rotate = rot(band_2, 30, reshape=False)\n",
    "        band_3_rotate = rot(band_3, 30, reshape=False)\n",
    "        image_rotate.append(np.dstack((band_1_rotate, band_2_rotate, band_3_rotate)))\n",
    "        \n",
    "    mirrorlr = np.array(image_mirror_lr)\n",
    "    mirrorud = np.array(image_mirror_ud)\n",
    "    rotated = np.array(image_rotate)\n",
    "    images = np.concatenate((images, mirrorlr, mirrorud, rotated))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X_5 = transform(train_5)\n",
    "train_y_5 = np.array(train_5 ['is_iceberg'])\n",
    "\n",
    "indx_tr = np.where(train_5.inc_angle > 0)\n",
    "\n",
    "train_y_5 = train_y_5[indx_tr[0]]\n",
    "train_X_5 = train_X_5[indx_tr[0], ...]\n",
    "\n",
    "train_X_5 = augment(train_X_5)\n",
    "train_y_5 = np.concatenate((train_y_5,train_y_5, train_y_5, train_y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_5():\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.layers.convolutional.Conv2D(64, kernel_size=(3,3), input_shape=(75,75,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.convolutional.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(keras.layers.convolutional.Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(keras.layers.convolutional.Conv2D(128, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.convolutional.Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "\n",
    "    model.add(keras.layers.Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(keras.layers.Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    mypotim=Adam(lr=0.001, decay=0.0)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer = mypotim, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "mcp_save = ModelCheckpoint('.model_5_weights.hdf5',\n",
    "                           save_best_only=True,\n",
    "                           monitor='val_loss',\n",
    "                           mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.1,\n",
    "                                   patience=5,\n",
    "                                   verbose=1,\n",
    "                                   epsilon=1e-4,\n",
    "                                   mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_5 = get_model_5()\n",
    "model_5.fit(train_X_5,\n",
    "            train_y_5,\n",
    "            batch_size=32,\n",
    "            epochs=50, \n",
    "            verbose=1,\n",
    "            validation_split=0.25,\n",
    "            callbacks=[early_stopping, reduce_lr_loss, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_5 = (model_5.evaluate(train_X_5,train_y_5,verbose=1))\n",
    "\n",
    "print('Train score:', score_5[0])\n",
    "print('Train accuracy:', score_5[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_5 = pd.read_json(\"test.json\")\n",
    "test_5.inc_angle = test_5.inc_angle.replace('na',0)\n",
    "test_X_5 = transform(test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test_5 = model_5.predict(test_X_5, verbose=1)\n",
    "submission_5 = pd.DataFrame({'id': test_5[\"id\"], 'is_iceberg': pred_test_5.reshape((pred_test_5.shape[0]))})\n",
    "submission_5.to_csv('model_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MODEL 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_6 = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75,75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75,75)\n",
    "        band_3 = band_1 + band_2 \n",
    "        \n",
    "        #Rescale\n",
    "        a = (band_1 - band_1.mean())/(band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean())/(band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean())/(band_3.max() - band_3.min())\n",
    "        \n",
    "        imgs.append(np.dstack((a,b,c)))\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_6 = get_scaled_imgs(train_6)\n",
    "Ytrain_6 = np.array(train_6['is_iceberg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_6.inc_angle = train_6.inc_angle.replace('na',0)\n",
    "idx_tr = np.where(train_6.inc_angle>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrain_6 = Ytrain_6[idx_tr[0]]\n",
    "Xtrain_6 = Xtrain_6[idx_tr[0],...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_more_images(imgs):\n",
    "    more_images = []\n",
    "    vert_flip_imgs = []\n",
    "    hori_flip_imgs = []\n",
    "    \n",
    "    for i in range(0,imgs.shape[0]):\n",
    "        a = imgs[i,:,:,0]\n",
    "        b = imgs[i,:,:,1]\n",
    "        c = imgs[i,:,:,2]\n",
    "        \n",
    "        av = cv2.flip(a,1)\n",
    "        ah = cv2.flip(a,0)\n",
    "        bv = cv2.flip(b,1)\n",
    "        bh = cv2.flip(b,0)\n",
    "        cv = cv2.flip(c,1)\n",
    "        ch = cv2.flip(c,0)\n",
    "        \n",
    "        vert_flip_imgs.append(np.dstack((av,bv,cv)))\n",
    "        hori_flip_imgs.append(np.dstack((ah,bh,ch)))\n",
    "        \n",
    "    v = np.array(vert_flip_imgs)\n",
    "    h = np.array(hori_flip_imgs)\n",
    "    more_images = np.concatenate((imgs,v,h))\n",
    "    \n",
    "    return more_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr_more_6 = get_more_images(Xtrain_6) \n",
    "Ytr_more_6 = np.concatenate((Ytrain_6,Ytrain_6,Ytrain_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel_6():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # CNN 1\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 2\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 3\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #CNN 4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # You must flatten the data for the dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense 1\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Dense 2\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_6 = getModel_6()\n",
    "earlyStopping = EarlyStopping(monitor = 'loss',\n",
    "                              patience =10,\n",
    "                              verbose = 0,\n",
    "                              mode = 'min'\n",
    "                             )\n",
    "mcp_save = ModelCheckpoint('.model_6_weights.hdf5',\n",
    "                           save_best_only=True,\n",
    "                           save_weights_only=True,\n",
    "                           monitor = 'loss',\n",
    "                           mode = 'min'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "datagen.fit(Xtr_more_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_6.fit_generator(datagen.flow(Xtr_more_6,\n",
    "          Ytr_more_6,\n",
    "          batch_size=32),\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "         callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_6.load_weights(filepath = '.model_6_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_6.load_weights(filepath = '.model_2_weights.hdf5')#gave a 98% accuracy\n",
    "\n",
    "score_6 = model_6.evaluate(Xtrain_6, Ytrain_6, verbose=1)\n",
    "print('Train score:', score_6[0])\n",
    "print('Train accuracy:', score_6[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_6 = pd.read_json('test.json')\n",
    "test_6.inc_angle = test_6.inc_angle.replace('na',0)\n",
    "Xtest_6 = (get_scaled_imgs(test_6))\n",
    "pred_test_6 = model_6.predict(Xtest_6)\n",
    "\n",
    "submission_6 = pd.DataFrame({'id': test_6[\"id\"], 'is_iceberg': pred_test_6.reshape((pred_test_6.shape[0]))})\n",
    "submission_6.to_csv('model_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Translate data to an image format\n",
    "def color_composite(data):\n",
    "    rgb_arrays = []\n",
    "    for i, row in data.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 / band_2\n",
    "\n",
    "        r = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n",
    "        g = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n",
    "        b = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        rgb_arrays.append(rgb)\n",
    "    return np.array(rgb_arrays)\n",
    "\n",
    "def denoise(X, weight, multichannel):\n",
    "    return np.asarray([denoise_tv_chambolle(item, weight=weight, multichannel=multichannel) for item in X])\n",
    "\n",
    "def smooth(X, sigma):\n",
    "    return np.asarray([gaussian(item, sigma=sigma) for item in X])\n",
    "\n",
    "def grayscale(X):\n",
    "    return np.asarray([rgb2gray(item) for item in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_7 = pd.read_json(\"train.json\")\n",
    "train_7.inc_angle = train_7.inc_angle.replace('na', 0)\n",
    "train_7.inc_angle = train_7.inc_angle.astype(float).fillna(0.0)\n",
    "train_all = True\n",
    "\n",
    "# These are train flags that required to train model more efficiently and \n",
    "# select proper model parameters\n",
    "train_b = True or train_all\n",
    "train_img = True or train_all\n",
    "train_total = True or train_all\n",
    "predict_submission = True and train_all\n",
    "\n",
    "clean_all = False\n",
    "clean_b = False or clean_all\n",
    "clean_img = False or clean_all\n",
    "\n",
    "load_all = False\n",
    "load_b = False or load_all\n",
    "load_img = False or load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(frame, labeled, smooth_rgb=0.2, smooth_gray=0.5,\n",
    "                   weight_rgb=0.05, weight_gray=0.05):\n",
    "    band_1, band_2, images = frame['band_1'].values, frame['band_2'].values, color_composite(frame)\n",
    "    to_arr = lambda x: np.asarray([np.asarray(item) for item in x])\n",
    "    band_1 = to_arr(band_1)\n",
    "    band_2 = to_arr(band_2)\n",
    "    band_3 = (band_1 + band_2) / 2\n",
    "    gray_reshape = lambda x: np.asarray([item.reshape(75, 75) for item in x])\n",
    "    # Make a picture format from flat vector\n",
    "    band_1 = gray_reshape(band_1)\n",
    "    band_2 = gray_reshape(band_2)\n",
    "    band_3 = gray_reshape(band_3)\n",
    "    print('Denoising and reshaping')\n",
    "    if train_b and clean_b:\n",
    "        # Smooth and denoise data\n",
    "        band_1 = smooth(denoise(band_1, weight_gray, False), smooth_gray)\n",
    "        print('Gray 1 done')\n",
    "        band_2 = smooth(denoise(band_2, weight_gray, False), smooth_gray)\n",
    "        print('Gray 2 done')\n",
    "        band_3 = smooth(denoise(band_3, weight_gray, False), smooth_gray)\n",
    "        print('Gray 3 done')\n",
    "    if train_img and clean_img:\n",
    "        images = smooth(denoise(images, weight_rgb, True), smooth_rgb)\n",
    "    print('RGB done')\n",
    "    tf_reshape = lambda x: np.asarray([item.reshape(75, 75, 1) for item in x])\n",
    "    band_1 = tf_reshape(band_1)\n",
    "    band_2 = tf_reshape(band_2)\n",
    "    band_3 = tf_reshape(band_3)\n",
    "    #images = tf_reshape(images)\n",
    "    band = np.concatenate([band_1, band_2, band_3], axis=3)\n",
    "    if labeled:\n",
    "        y = np.array(frame[\"is_iceberg\"])\n",
    "    else:\n",
    "        y = None\n",
    "    return y, band, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising and reshaping\n",
      "RGB done\n"
     ]
    }
   ],
   "source": [
    "y_train_7, X_b, X_images = create_dataset(train_7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_notebook(lr, decay, channels, relu_type='relu'):\n",
    "    # angle variable defines if we should use angle parameter or ignore it\n",
    "    input_1 = Input(shape=(75, 75, channels))\n",
    "\n",
    "    fcnn = Conv2D(32, kernel_size=(3, 3), activation=relu_type)(BatchNormalization()(input_1))\n",
    "    fcnn = MaxPooling2D((3, 3))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(64, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = BatchNormalization()(fcnn)\n",
    "    fcnn = Flatten()(fcnn)\n",
    "    local_input = input_1\n",
    "    partial_model = Model(input_1, fcnn)\n",
    "    dense = Dropout(0.2)(fcnn)\n",
    "    dense = Dense(256, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(128, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(64, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    # For some reason i've decided not to normalize angle data\n",
    "    output = Dense(1, activation=\"sigmoid\")(dense)\n",
    "    model = Model(local_input, output)\n",
    "    optimizer = Adam(lr=lr, decay=decay)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model, partial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_model(m_b, m_img, lr, decay):\n",
    "    input_b = Input(shape=(75, 75, 3))\n",
    "    input_img = Input(shape=(75, 75, 3))\n",
    "\n",
    "    m1 = m_b(input_b)\n",
    "    m2 = m_img(input_img)\n",
    "\n",
    "    # So, combine models and train perceptron based on that\n",
    "    # The iteresting idea is to use XGB for this task, but i actually hate this method\n",
    "    common = Concatenate()([m1, m2])\n",
    "    common = BatchNormalization()(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Dense(1024, activation='relu')(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Dense(512, activation='relu')(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    output = Dense(1, activation=\"sigmoid\")(common)\n",
    "    model = Model([input_b, input_img], output)\n",
    "    optimizer = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_flow_multi_inputs(I1, I2, y, batch_size):\n",
    "    gen1 = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             width_shift_range=0.,\n",
    "                             height_shift_range=0.,\n",
    "                             channel_shift_range=0,\n",
    "                             zoom_range=0.2,\n",
    "                             rotation_range=10)\n",
    "    gen2 = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             width_shift_range=0.,\n",
    "                             height_shift_range=0.,\n",
    "                             channel_shift_range=0,\n",
    "                             zoom_range=0.2,\n",
    "                             rotation_range=10)\n",
    "    genI1 = gen1.flow(I1, y, batch_size=batch_size, seed=57, shuffle=False)\n",
    "    genI2 = gen2.flow(I1, I2, batch_size=batch_size, seed=57, shuffle=False)\n",
    "    while True:\n",
    "        I1i = genI1.next()\n",
    "        I2i = genI2.next()\n",
    "        #print I1i[0].shape\n",
    "        np.testing.assert_array_equal(I2i[0], I1i[0])\n",
    "        yield [I1i[0], I2i[1]], I1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, epochs, checkpoint_name, X_train, y_train, val_data, verbose=2):\n",
    "    callbacks = [ModelCheckpoint(checkpoint_name, save_best_only=True, monitor='val_loss')]\n",
    "    datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.,\n",
    "                                   height_shift_range=0.,\n",
    "                                   channel_shift_range=0,\n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=10)\n",
    "    x_test, y_test = val_data\n",
    "    try:\n",
    "        model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                                    steps_per_epoch=len(X_train) / batch_size,\n",
    "                                    validation_data=(x_test, y_test), verbose=1,\n",
    "                                    callbacks=callbacks)\n",
    "    except KeyboardInterrupt:\n",
    "        if verbose > 0:\n",
    "            print('Interrupted')\n",
    "    if verbose > 0:\n",
    "        print('Loading model')\n",
    "    model.load_weights(filepath=checkpoint_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train a particular model\n",
    "def gen_model_weights(lr, decay, channels, relu, batch_size, epochs, path_name, data, verbose=2):\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = data\n",
    "    model, partial_model = get_model_notebook(lr, decay, channels, relu)\n",
    "    model = train_model(model, batch_size, epochs, path_name,\n",
    "                           X_train, y_train, (X_test, y_test), verbose=verbose)\n",
    "\n",
    "    if verbose > 0:\n",
    "        loss_val, acc_val = model.evaluate(X_val, y_val,\n",
    "                               verbose=0, batch_size=batch_size)\n",
    "\n",
    "        loss_train, acc_train = model.evaluate(X_test, y_test,\n",
    "                                       verbose=0, batch_size=batch_size)\n",
    "\n",
    "        print('Val/Train Loss:', str(loss_val) + '/' + str(loss_train), \\\n",
    "            'Val/Train Acc:', str(acc_val) + '/' + str(acc_train))\n",
    "    return model, partial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train all 3 models\n",
    "def train_models(dataset, lr, batch_size, max_epoch, verbose=2, return_model=False):\n",
    "    y_train, X_b, X_images = dataset\n",
    "    y_train_full, y_val,\\\n",
    "    X_b_full, X_b_val,\\\n",
    "    X_images_full, X_images_val = train_test_split(y_train, X_b, X_images, random_state=687, train_size=0.9)\n",
    "\n",
    "    y_train, y_test, \\\n",
    "    X_b_train, X_b_test, \\\n",
    "    X_images_train, X_images_test = train_test_split(y_train_full, X_b_full, X_images_full, random_state=576, train_size=0.85)\n",
    "\n",
    "    if train_b:\n",
    "        if verbose > 0:\n",
    "            print('Training bandwidth network')\n",
    "        data_b1 = (X_b_train, y_train, X_b_test, y_test, X_b_val, y_val)\n",
    "        model_b, model_b_cut = gen_model_weights(lr, 1e-6, 3, 'relu', batch_size, max_epoch, 'model_b',\n",
    "                                                 data=data_b1, verbose=verbose)\n",
    "\n",
    "    if train_img:\n",
    "        if verbose > 0:\n",
    "            print('Training image network')\n",
    "        data_images = (X_images_train, y_train, X_images_test, y_test, X_images_val, y_val)\n",
    "        model_images, model_images_cut = gen_model_weights(lr, 1e-6, 3, 'relu', batch_size, max_epoch, 'model_img',\n",
    "                                                       data_images, verbose=verbose)\n",
    "\n",
    "    if train_total:\n",
    "        common_model = combined_model(model_b_cut, model_images_cut, lr/2, 1e-7)\n",
    "        common_x_train = [X_b_full, X_images_full]\n",
    "        common_y_train = y_train_full\n",
    "        common_x_val = [X_b_val, X_images_val]\n",
    "        common_y_val = y_val\n",
    "        if verbose > 0:\n",
    "            print('Training common network')\n",
    "        callbacks = [ModelCheckpoint('common', save_best_only=True, monitor='val_loss')]\n",
    "        try:\n",
    "            common_model.fit_generator(gen_flow_multi_inputs(X_b_full, X_images_full, y_train_full, batch_size),\n",
    "                                         epochs=30,\n",
    "                                  steps_per_epoch=len(X_b_full) / batch_size,\n",
    "                                  validation_data=(common_x_val, common_y_val), verbose=1,\n",
    "                                  callbacks=callbacks)\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        common_model.load_weights(filepath='common')\n",
    "        loss_val, acc_val = common_model.evaluate(common_x_val, common_y_val,\n",
    "                                           verbose=0, batch_size=batch_size)\n",
    "        loss_train, acc_train = common_model.evaluate(common_x_train, common_y_train,\n",
    "                                                  verbose=0, batch_size=batch_size)\n",
    "        if verbose > 0:\n",
    "            print('Loss:', loss_val, 'Acc:', acc_val)\n",
    "    if return_model:\n",
    "        return common_model\n",
    "    else:\n",
    "        return (loss_train, acc_train), (loss_val, acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bandwidth network\n",
      "Epoch 1/250\n",
      "39/38 [==============================] - 11s 282ms/step - loss: 0.7152 - acc: 0.5298 - val_loss: 0.6803 - val_acc: 0.5253\n",
      "Epoch 2/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.6669 - acc: 0.5857 - val_loss: 0.6692 - val_acc: 0.6912\n",
      "Epoch 3/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.6553 - acc: 0.5797 - val_loss: 0.6662 - val_acc: 0.6129\n",
      "Epoch 4/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.6463 - acc: 0.5820 - val_loss: 0.6710 - val_acc: 0.5991\n",
      "Epoch 5/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.6539 - acc: 0.5946 - val_loss: 0.6835 - val_acc: 0.5576\n",
      "Epoch 6/250\n",
      "39/38 [==============================] - 8s 200ms/step - loss: 0.6382 - acc: 0.6148 - val_loss: 0.6900 - val_acc: 0.5253\n",
      "Epoch 7/250\n",
      "39/38 [==============================] - 8s 202ms/step - loss: 0.6325 - acc: 0.6001 - val_loss: 0.7026 - val_acc: 0.4839\n",
      "Epoch 8/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.6201 - acc: 0.6302 - val_loss: 0.7102 - val_acc: 0.4747\n",
      "Epoch 9/250\n",
      "39/38 [==============================] - 9s 221ms/step - loss: 0.6127 - acc: 0.6322 - val_loss: 0.7198 - val_acc: 0.4747\n",
      "Epoch 10/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.6166 - acc: 0.6243 - val_loss: 0.7198 - val_acc: 0.4793\n",
      "Epoch 11/250\n",
      "39/38 [==============================] - 9s 230ms/step - loss: 0.6185 - acc: 0.6267 - val_loss: 0.7175 - val_acc: 0.4885\n",
      "Epoch 12/250\n",
      "39/38 [==============================] - 9s 229ms/step - loss: 0.5892 - acc: 0.6640 - val_loss: 0.7342 - val_acc: 0.4747\n",
      "Epoch 13/250\n",
      "39/38 [==============================] - 9s 232ms/step - loss: 0.5920 - acc: 0.6793 - val_loss: 0.7446 - val_acc: 0.4747\n",
      "Epoch 14/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.5863 - acc: 0.6711 - val_loss: 0.7461 - val_acc: 0.4747\n",
      "Epoch 15/250\n",
      "39/38 [==============================] - 9s 233ms/step - loss: 0.5717 - acc: 0.6872 - val_loss: 0.7542 - val_acc: 0.4747\n",
      "Epoch 16/250\n",
      "39/38 [==============================] - 9s 224ms/step - loss: 0.5826 - acc: 0.6750 - val_loss: 0.7637 - val_acc: 0.4747\n",
      "Epoch 17/250\n",
      "39/38 [==============================] - 9s 239ms/step - loss: 0.5688 - acc: 0.6815 - val_loss: 0.7648 - val_acc: 0.4747\n",
      "Epoch 18/250\n",
      "39/38 [==============================] - 9s 235ms/step - loss: 0.5517 - acc: 0.7014 - val_loss: 0.7514 - val_acc: 0.4839\n",
      "Epoch 19/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.5455 - acc: 0.7065 - val_loss: 0.7547 - val_acc: 0.4747\n",
      "Epoch 20/250\n",
      "39/38 [==============================] - 9s 235ms/step - loss: 0.5401 - acc: 0.6974 - val_loss: 0.7575 - val_acc: 0.4747\n",
      "Epoch 21/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.5398 - acc: 0.7013 - val_loss: 0.7685 - val_acc: 0.4747\n",
      "Epoch 22/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.5347 - acc: 0.7183 - val_loss: 0.7607 - val_acc: 0.4839\n",
      "Epoch 23/250\n",
      "39/38 [==============================] - 9s 227ms/step - loss: 0.5095 - acc: 0.7312 - val_loss: 0.7567 - val_acc: 0.4839\n",
      "Epoch 24/250\n",
      "39/38 [==============================] - 9s 233ms/step - loss: 0.5118 - acc: 0.7343 - val_loss: 0.7572 - val_acc: 0.4747\n",
      "Epoch 25/250\n",
      "39/38 [==============================] - 9s 232ms/step - loss: 0.4940 - acc: 0.7553 - val_loss: 0.7600 - val_acc: 0.4839\n",
      "Epoch 26/250\n",
      "39/38 [==============================] - 9s 234ms/step - loss: 0.4772 - acc: 0.7656 - val_loss: 0.7079 - val_acc: 0.5346\n",
      "Epoch 27/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.4832 - acc: 0.7552 - val_loss: 0.7194 - val_acc: 0.5253\n",
      "Epoch 28/250\n",
      "39/38 [==============================] - 9s 235ms/step - loss: 0.4880 - acc: 0.7544 - val_loss: 0.7078 - val_acc: 0.5346\n",
      "Epoch 29/250\n",
      "39/38 [==============================] - 9s 239ms/step - loss: 0.4595 - acc: 0.7722 - val_loss: 0.7017 - val_acc: 0.5438\n",
      "Epoch 30/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.4779 - acc: 0.7656 - val_loss: 0.6761 - val_acc: 0.5530\n",
      "Epoch 31/250\n",
      "39/38 [==============================] - 9s 233ms/step - loss: 0.4529 - acc: 0.7744 - val_loss: 0.6939 - val_acc: 0.5576\n",
      "Epoch 32/250\n",
      "39/38 [==============================] - 9s 229ms/step - loss: 0.4512 - acc: 0.7809 - val_loss: 0.6208 - val_acc: 0.6129\n",
      "Epoch 33/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.4488 - acc: 0.7752 - val_loss: 0.6489 - val_acc: 0.6037\n",
      "Epoch 34/250\n",
      "39/38 [==============================] - 9s 218ms/step - loss: 0.4471 - acc: 0.7913 - val_loss: 0.6659 - val_acc: 0.5806\n",
      "Epoch 35/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.4294 - acc: 0.7880 - val_loss: 0.7041 - val_acc: 0.5484\n",
      "Epoch 36/250\n",
      "39/38 [==============================] - 9s 236ms/step - loss: 0.4262 - acc: 0.7907 - val_loss: 0.6866 - val_acc: 0.5806\n",
      "Epoch 37/250\n",
      "39/38 [==============================] - 9s 240ms/step - loss: 0.4327 - acc: 0.7944 - val_loss: 0.6315 - val_acc: 0.6129\n",
      "Epoch 38/250\n",
      "39/38 [==============================] - 9s 234ms/step - loss: 0.4430 - acc: 0.7847 - val_loss: 0.5873 - val_acc: 0.6313\n",
      "Epoch 39/250\n",
      "39/38 [==============================] - 9s 233ms/step - loss: 0.4236 - acc: 0.7991 - val_loss: 0.5897 - val_acc: 0.6221\n",
      "Epoch 40/250\n",
      "39/38 [==============================] - 9s 242ms/step - loss: 0.4279 - acc: 0.7978 - val_loss: 0.5871 - val_acc: 0.6267\n",
      "Epoch 41/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.4269 - acc: 0.7865 - val_loss: 0.6166 - val_acc: 0.6267\n",
      "Epoch 42/250\n",
      "39/38 [==============================] - 9s 223ms/step - loss: 0.4023 - acc: 0.8083 - val_loss: 0.6484 - val_acc: 0.6129\n",
      "Epoch 43/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.4189 - acc: 0.8074 - val_loss: 0.6890 - val_acc: 0.6175\n",
      "Epoch 44/250\n",
      "39/38 [==============================] - 9s 223ms/step - loss: 0.4149 - acc: 0.8002 - val_loss: 0.5746 - val_acc: 0.6636\n",
      "Epoch 45/250\n",
      "39/38 [==============================] - 9s 239ms/step - loss: 0.4144 - acc: 0.7897 - val_loss: 0.6341 - val_acc: 0.6544\n",
      "Epoch 46/250\n",
      "39/38 [==============================] - 10s 245ms/step - loss: 0.3857 - acc: 0.8184 - val_loss: 0.6411 - val_acc: 0.6544\n",
      "Epoch 47/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.3957 - acc: 0.8220 - val_loss: 0.5669 - val_acc: 0.7051\n",
      "Epoch 48/250\n",
      "39/38 [==============================] - 9s 229ms/step - loss: 0.4160 - acc: 0.8130 - val_loss: 0.5874 - val_acc: 0.7005\n",
      "Epoch 49/250\n",
      "39/38 [==============================] - 9s 240ms/step - loss: 0.3937 - acc: 0.8217 - val_loss: 0.5935 - val_acc: 0.6820\n",
      "Epoch 50/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.3974 - acc: 0.8131 - val_loss: 0.6640 - val_acc: 0.6590\n",
      "Epoch 51/250\n",
      "39/38 [==============================] - 9s 218ms/step - loss: 0.3746 - acc: 0.8210 - val_loss: 0.6403 - val_acc: 0.6682\n",
      "Epoch 52/250\n",
      "39/38 [==============================] - 9s 224ms/step - loss: 0.3968 - acc: 0.8137 - val_loss: 0.6412 - val_acc: 0.6728\n",
      "Epoch 53/250\n",
      "39/38 [==============================] - 9s 227ms/step - loss: 0.3835 - acc: 0.8250 - val_loss: 0.6262 - val_acc: 0.6820\n",
      "Epoch 54/250\n",
      "39/38 [==============================] - 9s 242ms/step - loss: 0.3988 - acc: 0.8063 - val_loss: 0.6061 - val_acc: 0.7005\n",
      "Epoch 55/250\n",
      "39/38 [==============================] - 9s 234ms/step - loss: 0.3943 - acc: 0.8074 - val_loss: 0.6542 - val_acc: 0.7051\n",
      "Epoch 56/250\n",
      "39/38 [==============================] - 9s 243ms/step - loss: 0.3592 - acc: 0.8227 - val_loss: 0.5473 - val_acc: 0.7235\n",
      "Epoch 57/250\n",
      "39/38 [==============================] - 9s 240ms/step - loss: 0.3969 - acc: 0.8161 - val_loss: 0.5720 - val_acc: 0.7143\n",
      "Epoch 58/250\n",
      "39/38 [==============================] - 9s 237ms/step - loss: 0.3830 - acc: 0.8218 - val_loss: 0.5874 - val_acc: 0.7189\n",
      "Epoch 59/250\n",
      "39/38 [==============================] - 10s 245ms/step - loss: 0.3845 - acc: 0.8227 - val_loss: 0.5191 - val_acc: 0.7373\n",
      "Epoch 60/250\n",
      "39/38 [==============================] - 9s 238ms/step - loss: 0.3848 - acc: 0.8097 - val_loss: 0.6280 - val_acc: 0.6774\n",
      "Epoch 61/250\n",
      "39/38 [==============================] - 9s 242ms/step - loss: 0.3688 - acc: 0.8363 - val_loss: 0.6034 - val_acc: 0.6912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/250\n",
      "39/38 [==============================] - 9s 227ms/step - loss: 0.3689 - acc: 0.8257 - val_loss: 0.5670 - val_acc: 0.7235\n",
      "Epoch 63/250\n",
      "39/38 [==============================] - 9s 230ms/step - loss: 0.3820 - acc: 0.8169 - val_loss: 0.6385 - val_acc: 0.7005\n",
      "Epoch 64/250\n",
      "39/38 [==============================] - 8s 216ms/step - loss: 0.3513 - acc: 0.8372 - val_loss: 0.5880 - val_acc: 0.7143\n",
      "Epoch 65/250\n",
      "39/38 [==============================] - 8s 218ms/step - loss: 0.3568 - acc: 0.8329 - val_loss: 0.5674 - val_acc: 0.7373\n",
      "Epoch 66/250\n",
      "39/38 [==============================] - 8s 216ms/step - loss: 0.3570 - acc: 0.8445 - val_loss: 0.5130 - val_acc: 0.7880\n",
      "Epoch 67/250\n",
      "39/38 [==============================] - 9s 224ms/step - loss: 0.3578 - acc: 0.8347 - val_loss: 0.5536 - val_acc: 0.7419\n",
      "Epoch 68/250\n",
      "39/38 [==============================] - 10s 244ms/step - loss: 0.3475 - acc: 0.8425 - val_loss: 0.4983 - val_acc: 0.7558\n",
      "Epoch 69/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.3301 - acc: 0.8573 - val_loss: 0.5658 - val_acc: 0.7419\n",
      "Epoch 70/250\n",
      "39/38 [==============================] - 9s 240ms/step - loss: 0.3440 - acc: 0.8429 - val_loss: 0.6304 - val_acc: 0.7097\n",
      "Epoch 71/250\n",
      "39/38 [==============================] - 9s 234ms/step - loss: 0.3453 - acc: 0.8451 - val_loss: 0.6233 - val_acc: 0.7189\n",
      "Epoch 72/250\n",
      "39/38 [==============================] - 9s 236ms/step - loss: 0.3403 - acc: 0.8477 - val_loss: 0.6616 - val_acc: 0.7051\n",
      "Epoch 73/250\n",
      "39/38 [==============================] - 9s 236ms/step - loss: 0.3620 - acc: 0.8275 - val_loss: 0.6973 - val_acc: 0.7189\n",
      "Epoch 74/250\n",
      "39/38 [==============================] - 9s 219ms/step - loss: 0.3707 - acc: 0.8274 - val_loss: 0.5717 - val_acc: 0.7327\n",
      "Epoch 75/250\n",
      "39/38 [==============================] - 8s 215ms/step - loss: 0.3482 - acc: 0.8453 - val_loss: 0.5609 - val_acc: 0.7327\n",
      "Epoch 76/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.3681 - acc: 0.8248 - val_loss: 0.6079 - val_acc: 0.7235\n",
      "Epoch 77/250\n",
      "39/38 [==============================] - 9s 227ms/step - loss: 0.3624 - acc: 0.8437 - val_loss: 0.6181 - val_acc: 0.7281\n",
      "Epoch 78/250\n",
      "39/38 [==============================] - 9s 223ms/step - loss: 0.3436 - acc: 0.8347 - val_loss: 0.6149 - val_acc: 0.7327\n",
      "Epoch 79/250\n",
      "39/38 [==============================] - 9s 237ms/step - loss: 0.3642 - acc: 0.8322 - val_loss: 0.6570 - val_acc: 0.7189\n",
      "Epoch 80/250\n",
      "39/38 [==============================] - 9s 239ms/step - loss: 0.3574 - acc: 0.8433 - val_loss: 0.6847 - val_acc: 0.7005\n",
      "Epoch 81/250\n",
      "39/38 [==============================] - 9s 240ms/step - loss: 0.3397 - acc: 0.8484 - val_loss: 0.5390 - val_acc: 0.7604\n",
      "Epoch 82/250\n",
      "39/38 [==============================] - 9s 237ms/step - loss: 0.3515 - acc: 0.8369 - val_loss: 0.6280 - val_acc: 0.7373\n",
      "Epoch 83/250\n",
      "39/38 [==============================] - 9s 233ms/step - loss: 0.3355 - acc: 0.8581 - val_loss: 0.5776 - val_acc: 0.7558\n",
      "Epoch 84/250\n",
      "39/38 [==============================] - 9s 243ms/step - loss: 0.3436 - acc: 0.8378 - val_loss: 0.5419 - val_acc: 0.7604\n",
      "Epoch 85/250\n",
      "39/38 [==============================] - 9s 225ms/step - loss: 0.3362 - acc: 0.8481 - val_loss: 0.5731 - val_acc: 0.7558\n",
      "Epoch 86/250\n",
      "39/38 [==============================] - 9s 236ms/step - loss: 0.3466 - acc: 0.8369 - val_loss: 0.6196 - val_acc: 0.7281\n",
      "Epoch 87/250\n",
      "39/38 [==============================] - 9s 228ms/step - loss: 0.3342 - acc: 0.8532 - val_loss: 0.6768 - val_acc: 0.7235\n",
      "Epoch 88/250\n",
      "39/38 [==============================] - 9s 232ms/step - loss: 0.3568 - acc: 0.8444 - val_loss: 0.5977 - val_acc: 0.7373\n",
      "Epoch 89/250\n",
      "39/38 [==============================] - 9s 227ms/step - loss: 0.3416 - acc: 0.8396 - val_loss: 0.6543 - val_acc: 0.7512\n",
      "Epoch 90/250\n",
      "39/38 [==============================] - 9s 232ms/step - loss: 0.3403 - acc: 0.8554 - val_loss: 0.6710 - val_acc: 0.7189\n",
      "Epoch 91/250\n",
      "39/38 [==============================] - 9s 231ms/step - loss: 0.3189 - acc: 0.8596 - val_loss: 0.5134 - val_acc: 0.7742\n",
      "Epoch 92/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.3303 - acc: 0.8501 - val_loss: 0.6385 - val_acc: 0.7327\n",
      "Epoch 93/250\n",
      "39/38 [==============================] - 9s 233ms/step - loss: 0.3419 - acc: 0.8443 - val_loss: 0.5939 - val_acc: 0.7419\n",
      "Epoch 94/250\n",
      "39/38 [==============================] - 8s 217ms/step - loss: 0.3349 - acc: 0.8491 - val_loss: 0.6606 - val_acc: 0.7281\n",
      "Epoch 95/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.3252 - acc: 0.8524 - val_loss: 0.7251 - val_acc: 0.7143\n",
      "Epoch 96/250\n",
      "39/38 [==============================] - 9s 230ms/step - loss: 0.3469 - acc: 0.8595 - val_loss: 0.5777 - val_acc: 0.7281\n",
      "Epoch 97/250\n",
      "39/38 [==============================] - 9s 236ms/step - loss: 0.3353 - acc: 0.8467 - val_loss: 0.5938 - val_acc: 0.7373\n",
      "Epoch 98/250\n",
      "39/38 [==============================] - 9s 228ms/step - loss: 0.3310 - acc: 0.8500 - val_loss: 0.5632 - val_acc: 0.7604\n",
      "Epoch 99/250\n",
      "39/38 [==============================] - 9s 235ms/step - loss: 0.3191 - acc: 0.8564 - val_loss: 0.5437 - val_acc: 0.7465\n",
      "Epoch 100/250\n",
      "39/38 [==============================] - 9s 237ms/step - loss: 0.3475 - acc: 0.8345 - val_loss: 0.5507 - val_acc: 0.7465\n",
      "Epoch 101/250\n",
      "39/38 [==============================] - 9s 229ms/step - loss: 0.3223 - acc: 0.8597 - val_loss: 0.6266 - val_acc: 0.7281\n",
      "Epoch 102/250\n",
      "39/38 [==============================] - 9s 232ms/step - loss: 0.3426 - acc: 0.8451 - val_loss: 0.6549 - val_acc: 0.7373\n",
      "Epoch 103/250\n",
      "39/38 [==============================] - 9s 229ms/step - loss: 0.3370 - acc: 0.8505 - val_loss: 0.6541 - val_acc: 0.7051\n",
      "Epoch 104/250\n",
      "39/38 [==============================] - 9s 232ms/step - loss: 0.3303 - acc: 0.8491 - val_loss: 0.5882 - val_acc: 0.7327\n",
      "Epoch 105/250\n",
      "39/38 [==============================] - 9s 224ms/step - loss: 0.3119 - acc: 0.8604 - val_loss: 0.5504 - val_acc: 0.7419\n",
      "Epoch 106/250\n",
      "39/38 [==============================] - 9s 229ms/step - loss: 0.3563 - acc: 0.8436 - val_loss: 0.5676 - val_acc: 0.7512\n",
      "Epoch 107/250\n",
      "39/38 [==============================] - 9s 234ms/step - loss: 0.3145 - acc: 0.8563 - val_loss: 0.5473 - val_acc: 0.7604\n",
      "Epoch 108/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.3066 - acc: 0.8620 - val_loss: 0.5272 - val_acc: 0.7742\n",
      "Epoch 109/250\n",
      "39/38 [==============================] - 9s 230ms/step - loss: 0.3109 - acc: 0.8516 - val_loss: 0.5746 - val_acc: 0.7558\n",
      "Epoch 110/250\n",
      "39/38 [==============================] - 8s 214ms/step - loss: 0.3385 - acc: 0.8433 - val_loss: 0.6205 - val_acc: 0.7558\n",
      "Epoch 111/250\n",
      "39/38 [==============================] - 9s 235ms/step - loss: 0.3341 - acc: 0.8434 - val_loss: 0.5333 - val_acc: 0.7788\n",
      "Epoch 112/250\n",
      "39/38 [==============================] - 9s 221ms/step - loss: 0.3066 - acc: 0.8586 - val_loss: 0.5514 - val_acc: 0.7604\n",
      "Epoch 113/250\n",
      "39/38 [==============================] - 9s 218ms/step - loss: 0.3127 - acc: 0.8531 - val_loss: 0.6085 - val_acc: 0.7558\n",
      "Epoch 114/250\n",
      "39/38 [==============================] - 8s 197ms/step - loss: 0.3141 - acc: 0.8644 - val_loss: 0.5760 - val_acc: 0.7512\n",
      "Epoch 115/250\n",
      "39/38 [==============================] - 8s 200ms/step - loss: 0.3120 - acc: 0.8660 - val_loss: 0.5429 - val_acc: 0.7650\n",
      "Epoch 116/250\n",
      "39/38 [==============================] - 8s 198ms/step - loss: 0.3297 - acc: 0.8489 - val_loss: 0.5391 - val_acc: 0.7696\n",
      "Epoch 117/250\n",
      "39/38 [==============================] - 8s 200ms/step - loss: 0.3347 - acc: 0.8426 - val_loss: 0.5757 - val_acc: 0.7558\n",
      "Epoch 118/250\n",
      "39/38 [==============================] - 8s 199ms/step - loss: 0.3444 - acc: 0.8303 - val_loss: 0.4549 - val_acc: 0.7880\n",
      "Epoch 119/250\n",
      "39/38 [==============================] - 8s 200ms/step - loss: 0.3060 - acc: 0.8667 - val_loss: 0.4932 - val_acc: 0.7788\n",
      "Epoch 120/250\n",
      "39/38 [==============================] - 8s 196ms/step - loss: 0.3195 - acc: 0.8660 - val_loss: 0.5374 - val_acc: 0.7696\n",
      "Epoch 121/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.3393 - acc: 0.8451 - val_loss: 0.5187 - val_acc: 0.7742\n",
      "Epoch 122/250\n",
      "39/38 [==============================] - 8s 199ms/step - loss: 0.3191 - acc: 0.8658 - val_loss: 0.5808 - val_acc: 0.7558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/250\n",
      "39/38 [==============================] - 8s 215ms/step - loss: 0.3067 - acc: 0.8677 - val_loss: 0.5877 - val_acc: 0.7465\n",
      "Epoch 124/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.3208 - acc: 0.8565 - val_loss: 0.4927 - val_acc: 0.7926\n",
      "Epoch 125/250\n",
      "39/38 [==============================] - 9s 220ms/step - loss: 0.3117 - acc: 0.8516 - val_loss: 0.4240 - val_acc: 0.8157\n",
      "Epoch 126/250\n",
      "39/38 [==============================] - 8s 215ms/step - loss: 0.3121 - acc: 0.8749 - val_loss: 0.4890 - val_acc: 0.7926\n",
      "Epoch 127/250\n",
      "39/38 [==============================] - 9s 220ms/step - loss: 0.3063 - acc: 0.8612 - val_loss: 0.5681 - val_acc: 0.7696\n",
      "Epoch 128/250\n",
      "39/38 [==============================] - 8s 214ms/step - loss: 0.3062 - acc: 0.8636 - val_loss: 0.5701 - val_acc: 0.7742\n",
      "Epoch 129/250\n",
      "39/38 [==============================] - 9s 221ms/step - loss: 0.3149 - acc: 0.8649 - val_loss: 0.4726 - val_acc: 0.7972\n",
      "Epoch 130/250\n",
      "39/38 [==============================] - 9s 220ms/step - loss: 0.3074 - acc: 0.8587 - val_loss: 0.6262 - val_acc: 0.7419\n",
      "Epoch 131/250\n",
      "39/38 [==============================] - 9s 220ms/step - loss: 0.3074 - acc: 0.8584 - val_loss: 0.5499 - val_acc: 0.7834\n",
      "Epoch 132/250\n",
      "39/38 [==============================] - 8s 214ms/step - loss: 0.2897 - acc: 0.8724 - val_loss: 0.5004 - val_acc: 0.7880\n",
      "Epoch 133/250\n",
      "39/38 [==============================] - 8s 213ms/step - loss: 0.3354 - acc: 0.8440 - val_loss: 0.5128 - val_acc: 0.7788\n",
      "Epoch 134/250\n",
      "39/38 [==============================] - 8s 212ms/step - loss: 0.3278 - acc: 0.8573 - val_loss: 0.6261 - val_acc: 0.7327\n",
      "Epoch 135/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.3077 - acc: 0.8556 - val_loss: 0.5394 - val_acc: 0.7834\n",
      "Epoch 136/250\n",
      "39/38 [==============================] - 9s 222ms/step - loss: 0.2972 - acc: 0.8525 - val_loss: 0.6050 - val_acc: 0.7419\n",
      "Epoch 137/250\n",
      "39/38 [==============================] - 8s 217ms/step - loss: 0.2982 - acc: 0.8668 - val_loss: 0.6156 - val_acc: 0.7327\n",
      "Epoch 138/250\n",
      "39/38 [==============================] - 9s 224ms/step - loss: 0.3106 - acc: 0.8612 - val_loss: 0.4514 - val_acc: 0.8065\n",
      "Epoch 139/250\n",
      "39/38 [==============================] - 9s 220ms/step - loss: 0.3176 - acc: 0.8652 - val_loss: 0.5570 - val_acc: 0.7696\n",
      "Epoch 140/250\n",
      "39/38 [==============================] - 9s 224ms/step - loss: 0.3157 - acc: 0.8700 - val_loss: 0.4594 - val_acc: 0.7972\n",
      "Epoch 141/250\n",
      "39/38 [==============================] - 9s 220ms/step - loss: 0.3062 - acc: 0.8661 - val_loss: 0.4703 - val_acc: 0.8065\n",
      "Epoch 142/250\n",
      "39/38 [==============================] - 9s 228ms/step - loss: 0.2887 - acc: 0.8701 - val_loss: 0.4964 - val_acc: 0.7926\n",
      "Epoch 143/250\n",
      "39/38 [==============================] - 9s 223ms/step - loss: 0.3210 - acc: 0.8643 - val_loss: 0.5222 - val_acc: 0.7788\n",
      "Epoch 144/250\n",
      "39/38 [==============================] - 9s 224ms/step - loss: 0.3085 - acc: 0.8675 - val_loss: 0.5116 - val_acc: 0.7972\n",
      "Epoch 145/250\n",
      "39/38 [==============================] - 9s 222ms/step - loss: 0.3266 - acc: 0.8539 - val_loss: 0.5217 - val_acc: 0.7834\n",
      "Epoch 146/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.3075 - acc: 0.8717 - val_loss: 0.5064 - val_acc: 0.7880\n",
      "Epoch 147/250\n",
      "39/38 [==============================] - 9s 218ms/step - loss: 0.3035 - acc: 0.8634 - val_loss: 0.5065 - val_acc: 0.7880\n",
      "Epoch 148/250\n",
      "39/38 [==============================] - 8s 216ms/step - loss: 0.3390 - acc: 0.8563 - val_loss: 0.7311 - val_acc: 0.7189\n",
      "Epoch 149/250\n",
      "39/38 [==============================] - 9s 221ms/step - loss: 0.3197 - acc: 0.8563 - val_loss: 0.5647 - val_acc: 0.7650\n",
      "Epoch 150/250\n",
      "39/38 [==============================] - 8s 212ms/step - loss: 0.2971 - acc: 0.8682 - val_loss: 0.6060 - val_acc: 0.7512\n",
      "Epoch 151/250\n",
      "39/38 [==============================] - 9s 226ms/step - loss: 0.2878 - acc: 0.8830 - val_loss: 0.4819 - val_acc: 0.7972\n",
      "Epoch 152/250\n",
      "39/38 [==============================] - 9s 221ms/step - loss: 0.3116 - acc: 0.8692 - val_loss: 0.4881 - val_acc: 0.7834\n",
      "Epoch 153/250\n",
      "39/38 [==============================] - 9s 230ms/step - loss: 0.2929 - acc: 0.8619 - val_loss: 0.4464 - val_acc: 0.8018\n",
      "Epoch 154/250\n",
      "39/38 [==============================] - 9s 222ms/step - loss: 0.2780 - acc: 0.8819 - val_loss: 0.4960 - val_acc: 0.7880\n",
      "Epoch 155/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.3047 - acc: 0.8683 - val_loss: 0.7296 - val_acc: 0.7189\n",
      "Epoch 156/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2962 - acc: 0.8673 - val_loss: 0.5124 - val_acc: 0.7926\n",
      "Epoch 157/250\n",
      "39/38 [==============================] - 8s 214ms/step - loss: 0.2793 - acc: 0.8798 - val_loss: 0.4501 - val_acc: 0.8065\n",
      "Epoch 158/250\n",
      "39/38 [==============================] - 9s 225ms/step - loss: 0.2991 - acc: 0.8745 - val_loss: 0.4688 - val_acc: 0.7926\n",
      "Epoch 159/250\n",
      "39/38 [==============================] - 9s 219ms/step - loss: 0.2974 - acc: 0.8552 - val_loss: 0.4559 - val_acc: 0.8157\n",
      "Epoch 160/250\n",
      "39/38 [==============================] - 8s 214ms/step - loss: 0.2755 - acc: 0.8812 - val_loss: 0.4359 - val_acc: 0.8111\n",
      "Epoch 161/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.3016 - acc: 0.8681 - val_loss: 0.5030 - val_acc: 0.7926\n",
      "Epoch 162/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2702 - acc: 0.8877 - val_loss: 0.6183 - val_acc: 0.7512\n",
      "Epoch 163/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2892 - acc: 0.8705 - val_loss: 0.5186 - val_acc: 0.7972\n",
      "Epoch 164/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.2705 - acc: 0.8877 - val_loss: 0.4826 - val_acc: 0.7926\n",
      "Epoch 165/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2795 - acc: 0.8803 - val_loss: 0.5509 - val_acc: 0.7972\n",
      "Epoch 166/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.3097 - acc: 0.8555 - val_loss: 0.5466 - val_acc: 0.8018\n",
      "Epoch 167/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2690 - acc: 0.8899 - val_loss: 0.3963 - val_acc: 0.8433\n",
      "Epoch 168/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2973 - acc: 0.8716 - val_loss: 0.5224 - val_acc: 0.7880\n",
      "Epoch 169/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2716 - acc: 0.8819 - val_loss: 0.5182 - val_acc: 0.8065\n",
      "Epoch 170/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.2768 - acc: 0.8794 - val_loss: 0.5291 - val_acc: 0.7972\n",
      "Epoch 171/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2978 - acc: 0.8725 - val_loss: 0.5418 - val_acc: 0.7650\n",
      "Epoch 172/250\n",
      "39/38 [==============================] - 8s 213ms/step - loss: 0.3125 - acc: 0.8794 - val_loss: 0.4479 - val_acc: 0.8111\n",
      "Epoch 173/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.3035 - acc: 0.8625 - val_loss: 0.4807 - val_acc: 0.7880\n",
      "Epoch 174/250\n",
      "39/38 [==============================] - 8s 212ms/step - loss: 0.2887 - acc: 0.8733 - val_loss: 0.4292 - val_acc: 0.8295\n",
      "Epoch 175/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2871 - acc: 0.8659 - val_loss: 0.4921 - val_acc: 0.8018\n",
      "Epoch 176/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2434 - acc: 0.8918 - val_loss: 0.4048 - val_acc: 0.8295\n",
      "Epoch 177/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2884 - acc: 0.8772 - val_loss: 0.4184 - val_acc: 0.8295\n",
      "Epoch 178/250\n",
      "39/38 [==============================] - 8s 213ms/step - loss: 0.2787 - acc: 0.8740 - val_loss: 0.5010 - val_acc: 0.7972\n",
      "Epoch 179/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2851 - acc: 0.8700 - val_loss: 0.4533 - val_acc: 0.8065\n",
      "Epoch 180/250\n",
      "39/38 [==============================] - 8s 212ms/step - loss: 0.2591 - acc: 0.8830 - val_loss: 0.4994 - val_acc: 0.8018\n",
      "Epoch 181/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2865 - acc: 0.8747 - val_loss: 0.4944 - val_acc: 0.8111\n",
      "Epoch 182/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.2699 - acc: 0.8693 - val_loss: 0.4528 - val_acc: 0.8203\n",
      "Epoch 183/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2621 - acc: 0.8886 - val_loss: 0.4687 - val_acc: 0.8157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/250\n",
      "39/38 [==============================] - 8s 212ms/step - loss: 0.3108 - acc: 0.8690 - val_loss: 0.5340 - val_acc: 0.7880\n",
      "Epoch 185/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2950 - acc: 0.8699 - val_loss: 0.4568 - val_acc: 0.8249\n",
      "Epoch 186/250\n",
      "39/38 [==============================] - 8s 212ms/step - loss: 0.2932 - acc: 0.8749 - val_loss: 0.5285 - val_acc: 0.7650\n",
      "Epoch 187/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2610 - acc: 0.8772 - val_loss: 0.4939 - val_acc: 0.8018\n",
      "Epoch 188/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.2660 - acc: 0.8893 - val_loss: 0.5249 - val_acc: 0.8018\n",
      "Epoch 189/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2821 - acc: 0.8746 - val_loss: 0.4803 - val_acc: 0.8065\n",
      "Epoch 190/250\n",
      "39/38 [==============================] - 8s 212ms/step - loss: 0.2698 - acc: 0.8782 - val_loss: 0.4754 - val_acc: 0.8018\n",
      "Epoch 191/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2856 - acc: 0.8811 - val_loss: 0.4975 - val_acc: 0.8111\n",
      "Epoch 192/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.2834 - acc: 0.8699 - val_loss: 0.4614 - val_acc: 0.8111\n",
      "Epoch 193/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2838 - acc: 0.8804 - val_loss: 0.4083 - val_acc: 0.7972\n",
      "Epoch 194/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.2932 - acc: 0.8602 - val_loss: 0.4727 - val_acc: 0.8249\n",
      "Epoch 195/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2828 - acc: 0.8665 - val_loss: 0.4531 - val_acc: 0.8249\n",
      "Epoch 196/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2985 - acc: 0.8645 - val_loss: 0.5010 - val_acc: 0.7742\n",
      "Epoch 197/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2624 - acc: 0.8814 - val_loss: 0.4542 - val_acc: 0.8157\n",
      "Epoch 198/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2593 - acc: 0.8902 - val_loss: 0.4242 - val_acc: 0.8341\n",
      "Epoch 199/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2641 - acc: 0.8780 - val_loss: 0.5184 - val_acc: 0.8157\n",
      "Epoch 200/250\n",
      "39/38 [==============================] - 8s 211ms/step - loss: 0.2858 - acc: 0.8780 - val_loss: 0.4522 - val_acc: 0.8249\n",
      "Epoch 201/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2939 - acc: 0.8705 - val_loss: 0.4547 - val_acc: 0.8203\n",
      "Epoch 202/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2668 - acc: 0.8867 - val_loss: 0.4917 - val_acc: 0.8018\n",
      "Epoch 203/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2680 - acc: 0.8894 - val_loss: 0.4921 - val_acc: 0.8111\n",
      "Epoch 204/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2704 - acc: 0.8902 - val_loss: 0.4647 - val_acc: 0.8111\n",
      "Epoch 205/250\n",
      "39/38 [==============================] - 8s 204ms/step - loss: 0.2634 - acc: 0.8820 - val_loss: 0.4645 - val_acc: 0.8295\n",
      "Epoch 206/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2792 - acc: 0.8809 - val_loss: 0.4380 - val_acc: 0.8157\n",
      "Epoch 207/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2613 - acc: 0.8901 - val_loss: 0.4527 - val_acc: 0.8295\n",
      "Epoch 208/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2635 - acc: 0.8835 - val_loss: 0.4374 - val_acc: 0.8341\n",
      "Epoch 209/250\n",
      "39/38 [==============================] - 8s 204ms/step - loss: 0.2607 - acc: 0.8878 - val_loss: 0.5552 - val_acc: 0.8065\n",
      "Epoch 210/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2619 - acc: 0.8894 - val_loss: 0.4648 - val_acc: 0.8249\n",
      "Epoch 211/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2916 - acc: 0.8723 - val_loss: 0.5128 - val_acc: 0.8249\n",
      "Epoch 212/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2701 - acc: 0.8753 - val_loss: 0.4778 - val_acc: 0.8249\n",
      "Epoch 213/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2667 - acc: 0.8883 - val_loss: 0.4977 - val_acc: 0.8249\n",
      "Epoch 214/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2570 - acc: 0.8946 - val_loss: 0.4903 - val_acc: 0.8111\n",
      "Epoch 215/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2505 - acc: 0.8890 - val_loss: 0.5008 - val_acc: 0.8249\n",
      "Epoch 216/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2479 - acc: 0.8909 - val_loss: 0.5434 - val_acc: 0.8203\n",
      "Epoch 217/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2741 - acc: 0.8843 - val_loss: 0.4886 - val_acc: 0.8203\n",
      "Epoch 218/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2587 - acc: 0.8909 - val_loss: 0.4934 - val_acc: 0.8157\n",
      "Epoch 219/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2686 - acc: 0.8755 - val_loss: 0.5411 - val_acc: 0.8065\n",
      "Epoch 220/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2684 - acc: 0.8804 - val_loss: 0.5733 - val_acc: 0.8111\n",
      "Epoch 221/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2744 - acc: 0.8852 - val_loss: 0.4596 - val_acc: 0.8295\n",
      "Epoch 222/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2726 - acc: 0.8778 - val_loss: 0.5137 - val_acc: 0.8157\n",
      "Epoch 223/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2565 - acc: 0.8865 - val_loss: 0.5597 - val_acc: 0.7604\n",
      "Epoch 224/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2599 - acc: 0.8893 - val_loss: 0.5017 - val_acc: 0.8065\n",
      "Epoch 225/250\n",
      "39/38 [==============================] - 8s 208ms/step - loss: 0.2942 - acc: 0.8746 - val_loss: 0.5606 - val_acc: 0.8065\n",
      "Epoch 226/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2625 - acc: 0.8844 - val_loss: 0.5053 - val_acc: 0.8295\n",
      "Epoch 227/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2760 - acc: 0.8828 - val_loss: 0.4600 - val_acc: 0.8341\n",
      "Epoch 228/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2536 - acc: 0.8875 - val_loss: 0.3871 - val_acc: 0.8525\n",
      "Epoch 229/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2589 - acc: 0.8942 - val_loss: 0.4945 - val_acc: 0.8065\n",
      "Epoch 230/250\n",
      "39/38 [==============================] - 8s 207ms/step - loss: 0.2727 - acc: 0.8850 - val_loss: 0.4167 - val_acc: 0.8433\n",
      "Epoch 231/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2588 - acc: 0.8966 - val_loss: 0.4686 - val_acc: 0.8249\n",
      "Epoch 232/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2584 - acc: 0.8836 - val_loss: 0.4076 - val_acc: 0.8433\n",
      "Epoch 233/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2626 - acc: 0.8886 - val_loss: 0.5394 - val_acc: 0.8065\n",
      "Epoch 234/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2588 - acc: 0.8820 - val_loss: 0.5365 - val_acc: 0.8157\n",
      "Epoch 235/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2433 - acc: 0.9060 - val_loss: 0.4714 - val_acc: 0.8341\n",
      "Epoch 236/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2573 - acc: 0.8918 - val_loss: 0.4771 - val_acc: 0.8387\n",
      "Epoch 237/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2526 - acc: 0.8867 - val_loss: 0.5108 - val_acc: 0.8065\n",
      "Epoch 238/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.2595 - acc: 0.8998 - val_loss: 0.5205 - val_acc: 0.8157\n",
      "Epoch 239/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2549 - acc: 0.8923 - val_loss: 0.4327 - val_acc: 0.8341\n",
      "Epoch 240/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2982 - acc: 0.8737 - val_loss: 0.4795 - val_acc: 0.8203\n",
      "Epoch 241/250\n",
      "39/38 [==============================] - 8s 213ms/step - loss: 0.2657 - acc: 0.8746 - val_loss: 0.4832 - val_acc: 0.8111\n",
      "Epoch 242/250\n",
      "39/38 [==============================] - 8s 213ms/step - loss: 0.2611 - acc: 0.8861 - val_loss: 0.3968 - val_acc: 0.8571\n",
      "Epoch 243/250\n",
      "39/38 [==============================] - 8s 218ms/step - loss: 0.2487 - acc: 0.8941 - val_loss: 0.4363 - val_acc: 0.8387\n",
      "Epoch 244/250\n",
      "39/38 [==============================] - 8s 213ms/step - loss: 0.2617 - acc: 0.8922 - val_loss: 0.3896 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/250\n",
      "39/38 [==============================] - 9s 218ms/step - loss: 0.2417 - acc: 0.8902 - val_loss: 0.3754 - val_acc: 0.8618\n",
      "Epoch 246/250\n",
      "39/38 [==============================] - 8s 214ms/step - loss: 0.2711 - acc: 0.8801 - val_loss: 0.4022 - val_acc: 0.8525\n",
      "Epoch 247/250\n",
      "39/38 [==============================] - 9s 221ms/step - loss: 0.2712 - acc: 0.8875 - val_loss: 0.4430 - val_acc: 0.8387\n",
      "Epoch 248/250\n",
      "39/38 [==============================] - 8s 209ms/step - loss: 0.2404 - acc: 0.8997 - val_loss: 0.4503 - val_acc: 0.8387\n",
      "Epoch 249/250\n",
      "39/38 [==============================] - 8s 210ms/step - loss: 0.2469 - acc: 0.8998 - val_loss: 0.4514 - val_acc: 0.8249\n",
      "Epoch 250/250\n",
      "39/38 [==============================] - 8s 205ms/step - loss: 0.2996 - acc: 0.8713 - val_loss: 0.4049 - val_acc: 0.8664\n",
      "Loading model\n",
      "Val/Train Loss: 0.328736434627/0.375361672332 Val/Train Acc: 0.875776397516/0.861751151524\n",
      "Training image network\n",
      "Epoch 1/250\n",
      "39/38 [==============================] - 11s 285ms/step - loss: 0.7538 - acc: 0.5112 - val_loss: 0.6912 - val_acc: 0.5853\n",
      "Epoch 2/250\n",
      "39/38 [==============================] - 8s 206ms/step - loss: 0.6902 - acc: 0.5739 - val_loss: 0.6868 - val_acc: 0.5253\n",
      "Epoch 3/250\n",
      "39/38 [==============================] - 7s 187ms/step - loss: 0.6541 - acc: 0.5964 - val_loss: 0.6819 - val_acc: 0.5253\n",
      "Epoch 4/250\n",
      "39/38 [==============================] - 8s 193ms/step - loss: 0.6572 - acc: 0.6148 - val_loss: 0.6744 - val_acc: 0.5253\n",
      "Epoch 5/250\n",
      "39/38 [==============================] - 7s 191ms/step - loss: 0.6124 - acc: 0.6468 - val_loss: 0.6659 - val_acc: 0.5253\n",
      "Epoch 6/250\n",
      "39/38 [==============================] - 8s 195ms/step - loss: 0.6154 - acc: 0.6615 - val_loss: 0.6652 - val_acc: 0.5253\n",
      "Epoch 7/250\n",
      "39/38 [==============================] - 7s 186ms/step - loss: 0.5962 - acc: 0.6612 - val_loss: 0.6577 - val_acc: 0.5253\n",
      "Epoch 8/250\n",
      "39/38 [==============================] - 8s 194ms/step - loss: 0.5874 - acc: 0.6694 - val_loss: 0.6353 - val_acc: 0.5300\n",
      "Epoch 9/250\n",
      "39/38 [==============================] - 8s 194ms/step - loss: 0.5692 - acc: 0.7036 - val_loss: 0.6052 - val_acc: 0.5853\n",
      "Epoch 10/250\n",
      "39/38 [==============================] - 8s 194ms/step - loss: 0.5598 - acc: 0.6972 - val_loss: 0.5908 - val_acc: 0.6129\n",
      "Epoch 11/250\n",
      "39/38 [==============================] - 8s 193ms/step - loss: 0.5485 - acc: 0.7129 - val_loss: 0.5677 - val_acc: 0.6636\n",
      "Epoch 12/250\n",
      "39/38 [==============================] - 7s 188ms/step - loss: 0.5474 - acc: 0.7176 - val_loss: 0.5411 - val_acc: 0.7097\n",
      "Epoch 13/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.5367 - acc: 0.7169 - val_loss: 0.5129 - val_acc: 0.7327\n",
      "Epoch 14/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.5177 - acc: 0.7379 - val_loss: 0.4934 - val_acc: 0.7604\n",
      "Epoch 15/250\n",
      "39/38 [==============================] - 7s 188ms/step - loss: 0.5233 - acc: 0.7263 - val_loss: 0.4948 - val_acc: 0.7512\n",
      "Epoch 16/250\n",
      "39/38 [==============================] - 7s 186ms/step - loss: 0.5139 - acc: 0.7271 - val_loss: 0.4861 - val_acc: 0.7696\n",
      "Epoch 17/250\n",
      "39/38 [==============================] - 7s 187ms/step - loss: 0.4996 - acc: 0.7397 - val_loss: 0.4628 - val_acc: 0.7834\n",
      "Epoch 18/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4948 - acc: 0.7426 - val_loss: 0.4567 - val_acc: 0.7788\n",
      "Epoch 19/250\n",
      "39/38 [==============================] - 7s 185ms/step - loss: 0.4875 - acc: 0.7482 - val_loss: 0.4517 - val_acc: 0.7742\n",
      "Epoch 20/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.5042 - acc: 0.7351 - val_loss: 0.4538 - val_acc: 0.7650\n",
      "Epoch 21/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.5156 - acc: 0.7317 - val_loss: 0.4496 - val_acc: 0.7558\n",
      "Epoch 22/250\n",
      "39/38 [==============================] - 7s 185ms/step - loss: 0.4971 - acc: 0.7521 - val_loss: 0.4472 - val_acc: 0.7604\n",
      "Epoch 23/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4789 - acc: 0.7634 - val_loss: 0.4405 - val_acc: 0.7788\n",
      "Epoch 24/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4796 - acc: 0.7535 - val_loss: 0.4450 - val_acc: 0.7604\n",
      "Epoch 25/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4723 - acc: 0.7456 - val_loss: 0.4304 - val_acc: 0.8018\n",
      "Epoch 26/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4706 - acc: 0.7648 - val_loss: 0.4339 - val_acc: 0.7742\n",
      "Epoch 27/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.4778 - acc: 0.7656 - val_loss: 0.4412 - val_acc: 0.7742\n",
      "Epoch 28/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4610 - acc: 0.7605 - val_loss: 0.4391 - val_acc: 0.7650\n",
      "Epoch 29/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.4721 - acc: 0.7569 - val_loss: 0.4434 - val_acc: 0.7650\n",
      "Epoch 30/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4659 - acc: 0.7640 - val_loss: 0.4215 - val_acc: 0.8065\n",
      "Epoch 31/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.4480 - acc: 0.7744 - val_loss: 0.4225 - val_acc: 0.8065\n",
      "Epoch 32/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4552 - acc: 0.7721 - val_loss: 0.4212 - val_acc: 0.8065\n",
      "Epoch 33/250\n",
      "39/38 [==============================] - 7s 186ms/step - loss: 0.4588 - acc: 0.7775 - val_loss: 0.4158 - val_acc: 0.8018\n",
      "Epoch 34/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.4470 - acc: 0.7720 - val_loss: 0.4183 - val_acc: 0.7880\n",
      "Epoch 35/250\n",
      "39/38 [==============================] - 7s 186ms/step - loss: 0.4313 - acc: 0.7900 - val_loss: 0.4095 - val_acc: 0.8157\n",
      "Epoch 36/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4339 - acc: 0.7923 - val_loss: 0.4072 - val_acc: 0.8157\n",
      "Epoch 37/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4515 - acc: 0.7809 - val_loss: 0.4137 - val_acc: 0.7880\n",
      "Epoch 38/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.4370 - acc: 0.7776 - val_loss: 0.4181 - val_acc: 0.7880\n",
      "Epoch 39/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4387 - acc: 0.7963 - val_loss: 0.4231 - val_acc: 0.7880\n",
      "Epoch 40/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.4568 - acc: 0.7728 - val_loss: 0.4164 - val_acc: 0.7834\n",
      "Epoch 41/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.4329 - acc: 0.7881 - val_loss: 0.4041 - val_acc: 0.7972\n",
      "Epoch 42/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4341 - acc: 0.7858 - val_loss: 0.3944 - val_acc: 0.8203\n",
      "Epoch 43/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4381 - acc: 0.7809 - val_loss: 0.3881 - val_acc: 0.8249\n",
      "Epoch 44/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4364 - acc: 0.7873 - val_loss: 0.3884 - val_acc: 0.8203\n",
      "Epoch 45/250\n",
      "39/38 [==============================] - 7s 187ms/step - loss: 0.4138 - acc: 0.8115 - val_loss: 0.4003 - val_acc: 0.7880\n",
      "Epoch 46/250\n",
      "39/38 [==============================] - 7s 186ms/step - loss: 0.4359 - acc: 0.7897 - val_loss: 0.3921 - val_acc: 0.8065\n",
      "Epoch 47/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.4175 - acc: 0.8034 - val_loss: 0.3875 - val_acc: 0.8111\n",
      "Epoch 48/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4265 - acc: 0.7833 - val_loss: 0.3901 - val_acc: 0.7834\n",
      "Epoch 49/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.4192 - acc: 0.7983 - val_loss: 0.3854 - val_acc: 0.7972\n",
      "Epoch 50/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.4164 - acc: 0.8024 - val_loss: 0.3863 - val_acc: 0.8111\n",
      "Epoch 51/250\n",
      "39/38 [==============================] - 7s 187ms/step - loss: 0.4005 - acc: 0.8083 - val_loss: 0.3806 - val_acc: 0.8111\n",
      "Epoch 52/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3947 - acc: 0.8027 - val_loss: 0.3788 - val_acc: 0.8065\n",
      "Epoch 53/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.4098 - acc: 0.8089 - val_loss: 0.3856 - val_acc: 0.8065\n",
      "Epoch 54/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.4052 - acc: 0.7968 - val_loss: 0.3943 - val_acc: 0.8111\n",
      "Epoch 55/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.4163 - acc: 0.7881 - val_loss: 0.3880 - val_acc: 0.8111\n",
      "Epoch 56/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3842 - acc: 0.8193 - val_loss: 0.3833 - val_acc: 0.8111\n",
      "Epoch 57/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3838 - acc: 0.8251 - val_loss: 0.3807 - val_acc: 0.8157\n",
      "Epoch 58/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3781 - acc: 0.8235 - val_loss: 0.3693 - val_acc: 0.8203\n",
      "Epoch 59/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.4082 - acc: 0.8010 - val_loss: 0.3785 - val_acc: 0.8203\n",
      "Epoch 60/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3921 - acc: 0.8162 - val_loss: 0.3769 - val_acc: 0.8111\n",
      "Epoch 61/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3963 - acc: 0.8219 - val_loss: 0.3640 - val_acc: 0.8111\n",
      "Epoch 62/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3765 - acc: 0.8378 - val_loss: 0.3738 - val_acc: 0.8157\n",
      "Epoch 63/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3759 - acc: 0.8251 - val_loss: 0.3587 - val_acc: 0.8295\n",
      "Epoch 64/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3749 - acc: 0.8161 - val_loss: 0.3616 - val_acc: 0.8295\n",
      "Epoch 65/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3839 - acc: 0.8074 - val_loss: 0.3612 - val_acc: 0.8111\n",
      "Epoch 66/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3849 - acc: 0.8241 - val_loss: 0.3633 - val_acc: 0.8203\n",
      "Epoch 67/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3942 - acc: 0.8095 - val_loss: 0.3711 - val_acc: 0.8295\n",
      "Epoch 68/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3667 - acc: 0.8428 - val_loss: 0.3590 - val_acc: 0.8341\n",
      "Epoch 69/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3478 - acc: 0.8355 - val_loss: 0.3719 - val_acc: 0.8341\n",
      "Epoch 70/250\n",
      "39/38 [==============================] - 7s 177ms/step - loss: 0.3781 - acc: 0.8263 - val_loss: 0.3643 - val_acc: 0.8249\n",
      "Epoch 71/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3747 - acc: 0.8219 - val_loss: 0.3761 - val_acc: 0.8018\n",
      "Epoch 72/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3627 - acc: 0.8218 - val_loss: 0.3688 - val_acc: 0.8157\n",
      "Epoch 73/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3846 - acc: 0.8184 - val_loss: 0.3605 - val_acc: 0.8341\n",
      "Epoch 74/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3692 - acc: 0.8281 - val_loss: 0.3660 - val_acc: 0.8249\n",
      "Epoch 75/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3701 - acc: 0.8306 - val_loss: 0.3641 - val_acc: 0.8157\n",
      "Epoch 76/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3570 - acc: 0.8339 - val_loss: 0.3513 - val_acc: 0.8341\n",
      "Epoch 77/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3715 - acc: 0.8346 - val_loss: 0.3621 - val_acc: 0.8387\n",
      "Epoch 78/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3722 - acc: 0.8248 - val_loss: 0.3550 - val_acc: 0.8387\n",
      "Epoch 79/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3828 - acc: 0.8120 - val_loss: 0.3529 - val_acc: 0.8341\n",
      "Epoch 80/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.3578 - acc: 0.8370 - val_loss: 0.3563 - val_acc: 0.8157\n",
      "Epoch 81/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3519 - acc: 0.8216 - val_loss: 0.3600 - val_acc: 0.8157\n",
      "Epoch 82/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3651 - acc: 0.8355 - val_loss: 0.3561 - val_acc: 0.8157\n",
      "Epoch 83/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3606 - acc: 0.8336 - val_loss: 0.3614 - val_acc: 0.8249\n",
      "Epoch 84/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3692 - acc: 0.8225 - val_loss: 0.3508 - val_acc: 0.8249\n",
      "Epoch 85/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.3428 - acc: 0.8299 - val_loss: 0.3471 - val_acc: 0.8203\n",
      "Epoch 86/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3583 - acc: 0.8355 - val_loss: 0.3454 - val_acc: 0.8341\n",
      "Epoch 87/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3569 - acc: 0.8370 - val_loss: 0.3348 - val_acc: 0.8295\n",
      "Epoch 88/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3321 - acc: 0.8321 - val_loss: 0.3321 - val_acc: 0.8387\n",
      "Epoch 89/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3460 - acc: 0.8312 - val_loss: 0.3415 - val_acc: 0.8203\n",
      "Epoch 90/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3718 - acc: 0.8258 - val_loss: 0.3482 - val_acc: 0.8433\n",
      "Epoch 91/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3233 - acc: 0.8540 - val_loss: 0.3487 - val_acc: 0.8295\n",
      "Epoch 92/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3369 - acc: 0.8328 - val_loss: 0.3529 - val_acc: 0.8387\n",
      "Epoch 93/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3194 - acc: 0.8611 - val_loss: 0.3457 - val_acc: 0.8295\n",
      "Epoch 94/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3595 - acc: 0.8323 - val_loss: 0.3489 - val_acc: 0.8249\n",
      "Epoch 95/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3459 - acc: 0.8347 - val_loss: 0.3480 - val_acc: 0.8203\n",
      "Epoch 96/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3414 - acc: 0.8352 - val_loss: 0.3419 - val_acc: 0.8249\n",
      "Epoch 97/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3549 - acc: 0.8257 - val_loss: 0.3446 - val_acc: 0.8341\n",
      "Epoch 98/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3450 - acc: 0.8409 - val_loss: 0.3377 - val_acc: 0.8433\n",
      "Epoch 99/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3546 - acc: 0.8280 - val_loss: 0.3378 - val_acc: 0.8479\n",
      "Epoch 100/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3627 - acc: 0.8338 - val_loss: 0.3363 - val_acc: 0.8525\n",
      "Epoch 101/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3498 - acc: 0.8323 - val_loss: 0.3366 - val_acc: 0.8249\n",
      "Epoch 102/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.3239 - acc: 0.8452 - val_loss: 0.3284 - val_acc: 0.8387\n",
      "Epoch 103/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3322 - acc: 0.8428 - val_loss: 0.3326 - val_acc: 0.8203\n",
      "Epoch 104/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3317 - acc: 0.8477 - val_loss: 0.3389 - val_acc: 0.8295\n",
      "Epoch 105/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3447 - acc: 0.8396 - val_loss: 0.3403 - val_acc: 0.8249\n",
      "Epoch 106/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3341 - acc: 0.8491 - val_loss: 0.3459 - val_acc: 0.8341\n",
      "Epoch 107/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3269 - acc: 0.8605 - val_loss: 0.3365 - val_acc: 0.8295\n",
      "Epoch 108/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.3273 - acc: 0.8402 - val_loss: 0.3396 - val_acc: 0.8249\n",
      "Epoch 109/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3308 - acc: 0.8516 - val_loss: 0.3278 - val_acc: 0.8387\n",
      "Epoch 110/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3411 - acc: 0.8401 - val_loss: 0.3355 - val_acc: 0.8295\n",
      "Epoch 111/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3200 - acc: 0.8604 - val_loss: 0.3381 - val_acc: 0.8249\n",
      "Epoch 112/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3236 - acc: 0.8549 - val_loss: 0.3438 - val_acc: 0.8203\n",
      "Epoch 113/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3430 - acc: 0.8370 - val_loss: 0.3443 - val_acc: 0.8249\n",
      "Epoch 114/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3444 - acc: 0.8402 - val_loss: 0.3297 - val_acc: 0.8525\n",
      "Epoch 115/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3317 - acc: 0.8401 - val_loss: 0.3607 - val_acc: 0.8018\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3171 - acc: 0.8540 - val_loss: 0.3360 - val_acc: 0.8157\n",
      "Epoch 117/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3408 - acc: 0.8402 - val_loss: 0.3385 - val_acc: 0.8203\n",
      "Epoch 118/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3534 - acc: 0.8323 - val_loss: 0.3470 - val_acc: 0.8295\n",
      "Epoch 119/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3086 - acc: 0.8636 - val_loss: 0.3237 - val_acc: 0.8295\n",
      "Epoch 120/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3147 - acc: 0.8620 - val_loss: 0.3344 - val_acc: 0.8387\n",
      "Epoch 121/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3117 - acc: 0.8449 - val_loss: 0.3455 - val_acc: 0.8157\n",
      "Epoch 122/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3157 - acc: 0.8557 - val_loss: 0.3386 - val_acc: 0.8433\n",
      "Epoch 123/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3055 - acc: 0.8524 - val_loss: 0.3259 - val_acc: 0.8295\n",
      "Epoch 124/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3429 - acc: 0.8425 - val_loss: 0.3580 - val_acc: 0.8249\n",
      "Epoch 125/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3090 - acc: 0.8532 - val_loss: 0.3393 - val_acc: 0.8295\n",
      "Epoch 126/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3290 - acc: 0.8497 - val_loss: 0.3400 - val_acc: 0.8341\n",
      "Epoch 127/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3205 - acc: 0.8408 - val_loss: 0.3457 - val_acc: 0.8157\n",
      "Epoch 128/250\n",
      "39/38 [==============================] - 7s 190ms/step - loss: 0.3328 - acc: 0.8491 - val_loss: 0.3275 - val_acc: 0.8433\n",
      "Epoch 129/250\n",
      "39/38 [==============================] - 7s 177ms/step - loss: 0.3101 - acc: 0.8481 - val_loss: 0.3403 - val_acc: 0.8249\n",
      "Epoch 130/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3146 - acc: 0.8484 - val_loss: 0.3236 - val_acc: 0.8479\n",
      "Epoch 131/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3336 - acc: 0.8402 - val_loss: 0.3388 - val_acc: 0.8065\n",
      "Epoch 132/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3421 - acc: 0.8473 - val_loss: 0.3197 - val_acc: 0.8341\n",
      "Epoch 133/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.3269 - acc: 0.8491 - val_loss: 0.3178 - val_acc: 0.8387\n",
      "Epoch 134/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3075 - acc: 0.8572 - val_loss: 0.3261 - val_acc: 0.8479\n",
      "Epoch 135/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2946 - acc: 0.8589 - val_loss: 0.3175 - val_acc: 0.8433\n",
      "Epoch 136/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3242 - acc: 0.8489 - val_loss: 0.3211 - val_acc: 0.8525\n",
      "Epoch 137/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3328 - acc: 0.8489 - val_loss: 0.3228 - val_acc: 0.8341\n",
      "Epoch 138/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3181 - acc: 0.8451 - val_loss: 0.3348 - val_acc: 0.8018\n",
      "Epoch 139/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3329 - acc: 0.8551 - val_loss: 0.3292 - val_acc: 0.8203\n",
      "Epoch 140/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3153 - acc: 0.8508 - val_loss: 0.3292 - val_acc: 0.8249\n",
      "Epoch 141/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2980 - acc: 0.8588 - val_loss: 0.3126 - val_acc: 0.8295\n",
      "Epoch 142/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2931 - acc: 0.8644 - val_loss: 0.3349 - val_acc: 0.8249\n",
      "Epoch 143/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3093 - acc: 0.8626 - val_loss: 0.3147 - val_acc: 0.8341\n",
      "Epoch 144/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3100 - acc: 0.8468 - val_loss: 0.3404 - val_acc: 0.8111\n",
      "Epoch 145/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3004 - acc: 0.8645 - val_loss: 0.3272 - val_acc: 0.8249\n",
      "Epoch 146/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3012 - acc: 0.8699 - val_loss: 0.3530 - val_acc: 0.8111\n",
      "Epoch 147/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2973 - acc: 0.8573 - val_loss: 0.3408 - val_acc: 0.8479\n",
      "Epoch 148/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3137 - acc: 0.8487 - val_loss: 0.3281 - val_acc: 0.8203\n",
      "Epoch 149/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.3175 - acc: 0.8619 - val_loss: 0.3123 - val_acc: 0.8341\n",
      "Epoch 150/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2990 - acc: 0.8675 - val_loss: 0.3188 - val_acc: 0.8433\n",
      "Epoch 151/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3024 - acc: 0.8611 - val_loss: 0.3368 - val_acc: 0.8111\n",
      "Epoch 152/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2827 - acc: 0.8693 - val_loss: 0.3264 - val_acc: 0.8111\n",
      "Epoch 153/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3167 - acc: 0.8579 - val_loss: 0.3283 - val_acc: 0.8203\n",
      "Epoch 154/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2946 - acc: 0.8596 - val_loss: 0.3319 - val_acc: 0.8295\n",
      "Epoch 155/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3065 - acc: 0.8684 - val_loss: 0.3277 - val_acc: 0.8295\n",
      "Epoch 156/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2909 - acc: 0.8690 - val_loss: 0.3533 - val_acc: 0.8203\n",
      "Epoch 157/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3298 - acc: 0.8409 - val_loss: 0.3306 - val_acc: 0.8203\n",
      "Epoch 158/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2929 - acc: 0.8596 - val_loss: 0.3250 - val_acc: 0.8203\n",
      "Epoch 159/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3203 - acc: 0.8484 - val_loss: 0.3303 - val_acc: 0.8295\n",
      "Epoch 160/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.3025 - acc: 0.8588 - val_loss: 0.3343 - val_acc: 0.8249\n",
      "Epoch 161/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3011 - acc: 0.8684 - val_loss: 0.3559 - val_acc: 0.7926\n",
      "Epoch 162/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.3131 - acc: 0.8555 - val_loss: 0.3296 - val_acc: 0.8295\n",
      "Epoch 163/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3167 - acc: 0.8491 - val_loss: 0.3268 - val_acc: 0.8433\n",
      "Epoch 164/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3332 - acc: 0.8578 - val_loss: 0.3357 - val_acc: 0.8157\n",
      "Epoch 165/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2971 - acc: 0.8739 - val_loss: 0.3508 - val_acc: 0.8065\n",
      "Epoch 166/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2850 - acc: 0.8730 - val_loss: 0.3215 - val_acc: 0.8387\n",
      "Epoch 167/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.3057 - acc: 0.8547 - val_loss: 0.3442 - val_acc: 0.8111\n",
      "Epoch 168/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2990 - acc: 0.8644 - val_loss: 0.3244 - val_acc: 0.8295\n",
      "Epoch 169/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2940 - acc: 0.8732 - val_loss: 0.3285 - val_acc: 0.8249\n",
      "Epoch 170/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.3095 - acc: 0.8635 - val_loss: 0.3264 - val_acc: 0.8249\n",
      "Epoch 171/250\n",
      "39/38 [==============================] - 7s 188ms/step - loss: 0.2948 - acc: 0.8682 - val_loss: 0.3329 - val_acc: 0.8295\n",
      "Epoch 172/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2937 - acc: 0.8596 - val_loss: 0.3304 - val_acc: 0.8295\n",
      "Epoch 173/250\n",
      "39/38 [==============================] - 7s 177ms/step - loss: 0.3054 - acc: 0.8636 - val_loss: 0.3321 - val_acc: 0.8203\n",
      "Epoch 174/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2936 - acc: 0.8620 - val_loss: 0.3337 - val_acc: 0.8249\n",
      "Epoch 175/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2779 - acc: 0.8644 - val_loss: 0.3302 - val_acc: 0.8295\n",
      "Epoch 176/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2970 - acc: 0.8596 - val_loss: 0.3568 - val_acc: 0.8157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2940 - acc: 0.8603 - val_loss: 0.3449 - val_acc: 0.8111\n",
      "Epoch 178/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3130 - acc: 0.8520 - val_loss: 0.4137 - val_acc: 0.8065\n",
      "Epoch 179/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2893 - acc: 0.8596 - val_loss: 0.3256 - val_acc: 0.8203\n",
      "Epoch 180/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2900 - acc: 0.8725 - val_loss: 0.3268 - val_acc: 0.8203\n",
      "Epoch 181/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3016 - acc: 0.8612 - val_loss: 0.3472 - val_acc: 0.8111\n",
      "Epoch 182/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.3021 - acc: 0.8587 - val_loss: 0.3284 - val_acc: 0.8341\n",
      "Epoch 183/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2934 - acc: 0.8538 - val_loss: 0.3849 - val_acc: 0.8065\n",
      "Epoch 184/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2920 - acc: 0.8595 - val_loss: 0.3358 - val_acc: 0.8249\n",
      "Epoch 185/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2928 - acc: 0.8677 - val_loss: 0.3365 - val_acc: 0.8203\n",
      "Epoch 186/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2835 - acc: 0.8667 - val_loss: 0.3230 - val_acc: 0.8249\n",
      "Epoch 187/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2895 - acc: 0.8716 - val_loss: 0.3537 - val_acc: 0.8018\n",
      "Epoch 188/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2940 - acc: 0.8572 - val_loss: 0.3244 - val_acc: 0.8295\n",
      "Epoch 189/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2910 - acc: 0.8604 - val_loss: 0.3412 - val_acc: 0.8203\n",
      "Epoch 190/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2959 - acc: 0.8605 - val_loss: 0.3166 - val_acc: 0.8387\n",
      "Epoch 191/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2660 - acc: 0.8820 - val_loss: 0.3458 - val_acc: 0.8249\n",
      "Epoch 192/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.3058 - acc: 0.8653 - val_loss: 0.3706 - val_acc: 0.8018\n",
      "Epoch 193/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2734 - acc: 0.8706 - val_loss: 0.3484 - val_acc: 0.8203\n",
      "Epoch 194/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2844 - acc: 0.8628 - val_loss: 0.3229 - val_acc: 0.8341\n",
      "Epoch 195/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2765 - acc: 0.8756 - val_loss: 0.3460 - val_acc: 0.8203\n",
      "Epoch 196/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2801 - acc: 0.8757 - val_loss: 0.3416 - val_acc: 0.8111\n",
      "Epoch 197/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2918 - acc: 0.8667 - val_loss: 0.3352 - val_acc: 0.8249\n",
      "Epoch 198/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2950 - acc: 0.8717 - val_loss: 0.3257 - val_acc: 0.8295\n",
      "Epoch 199/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2755 - acc: 0.8701 - val_loss: 0.3371 - val_acc: 0.8341\n",
      "Epoch 200/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2940 - acc: 0.8700 - val_loss: 0.3235 - val_acc: 0.8341\n",
      "Epoch 201/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2721 - acc: 0.8733 - val_loss: 0.3044 - val_acc: 0.8479\n",
      "Epoch 202/250\n",
      "39/38 [==============================] - 7s 177ms/step - loss: 0.2982 - acc: 0.8722 - val_loss: 0.3314 - val_acc: 0.8249\n",
      "Epoch 203/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2715 - acc: 0.8773 - val_loss: 0.3146 - val_acc: 0.8433\n",
      "Epoch 204/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2712 - acc: 0.8820 - val_loss: 0.3077 - val_acc: 0.8479\n",
      "Epoch 205/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2951 - acc: 0.8690 - val_loss: 0.3183 - val_acc: 0.8479\n",
      "Epoch 206/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2892 - acc: 0.8700 - val_loss: 0.3115 - val_acc: 0.8479\n",
      "Epoch 207/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2846 - acc: 0.8653 - val_loss: 0.3142 - val_acc: 0.8433\n",
      "Epoch 208/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2969 - acc: 0.8628 - val_loss: 0.3172 - val_acc: 0.8525\n",
      "Epoch 209/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2860 - acc: 0.8660 - val_loss: 0.3244 - val_acc: 0.8341\n",
      "Epoch 210/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2707 - acc: 0.8794 - val_loss: 0.3093 - val_acc: 0.8433\n",
      "Epoch 211/250\n",
      "39/38 [==============================] - 7s 177ms/step - loss: 0.2747 - acc: 0.8683 - val_loss: 0.3699 - val_acc: 0.8018\n",
      "Epoch 212/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2976 - acc: 0.8658 - val_loss: 0.3353 - val_acc: 0.8295\n",
      "Epoch 213/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2886 - acc: 0.8693 - val_loss: 0.3455 - val_acc: 0.8295\n",
      "Epoch 214/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2831 - acc: 0.8691 - val_loss: 0.3862 - val_acc: 0.8018\n",
      "Epoch 215/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2814 - acc: 0.8741 - val_loss: 0.3278 - val_acc: 0.8249\n",
      "Epoch 216/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2766 - acc: 0.8677 - val_loss: 0.3369 - val_acc: 0.8341\n",
      "Epoch 217/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2795 - acc: 0.8674 - val_loss: 0.3336 - val_acc: 0.8249\n",
      "Epoch 218/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2706 - acc: 0.8699 - val_loss: 0.3336 - val_acc: 0.8295\n",
      "Epoch 219/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2804 - acc: 0.8586 - val_loss: 0.3423 - val_acc: 0.8249\n",
      "Epoch 220/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2536 - acc: 0.8869 - val_loss: 0.3227 - val_acc: 0.8341\n",
      "Epoch 221/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2884 - acc: 0.8756 - val_loss: 0.3817 - val_acc: 0.8111\n",
      "Epoch 222/250\n",
      "39/38 [==============================] - 7s 184ms/step - loss: 0.2731 - acc: 0.8733 - val_loss: 0.3468 - val_acc: 0.8249\n",
      "Epoch 223/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2810 - acc: 0.8733 - val_loss: 0.3574 - val_acc: 0.8157\n",
      "Epoch 224/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2519 - acc: 0.8909 - val_loss: 0.3376 - val_acc: 0.8295\n",
      "Epoch 225/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2750 - acc: 0.8707 - val_loss: 0.3250 - val_acc: 0.8295\n",
      "Epoch 226/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2939 - acc: 0.8651 - val_loss: 0.3150 - val_acc: 0.8479\n",
      "Epoch 227/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2930 - acc: 0.8644 - val_loss: 0.3206 - val_acc: 0.8479\n",
      "Epoch 228/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2658 - acc: 0.8715 - val_loss: 0.3229 - val_acc: 0.8387\n",
      "Epoch 229/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2665 - acc: 0.8732 - val_loss: 0.3499 - val_acc: 0.8157\n",
      "Epoch 230/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2896 - acc: 0.8700 - val_loss: 0.3546 - val_acc: 0.8157\n",
      "Epoch 231/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2834 - acc: 0.8644 - val_loss: 0.3304 - val_acc: 0.8249\n",
      "Epoch 232/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2768 - acc: 0.8705 - val_loss: 0.3217 - val_acc: 0.8479\n",
      "Epoch 233/250\n",
      "39/38 [==============================] - 7s 183ms/step - loss: 0.2779 - acc: 0.8740 - val_loss: 0.3253 - val_acc: 0.8341\n",
      "Epoch 234/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2765 - acc: 0.8755 - val_loss: 0.3162 - val_acc: 0.8341\n",
      "Epoch 235/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2730 - acc: 0.8756 - val_loss: 0.3147 - val_acc: 0.8479\n",
      "Epoch 236/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2739 - acc: 0.8812 - val_loss: 0.3366 - val_acc: 0.8295\n",
      "Epoch 237/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2995 - acc: 0.8611 - val_loss: 0.3697 - val_acc: 0.8295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2710 - acc: 0.8780 - val_loss: 0.3358 - val_acc: 0.8295\n",
      "Epoch 239/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2396 - acc: 0.8830 - val_loss: 0.3343 - val_acc: 0.8387\n",
      "Epoch 240/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2616 - acc: 0.8802 - val_loss: 0.3279 - val_acc: 0.8387\n",
      "Epoch 241/250\n",
      "39/38 [==============================] - 7s 177ms/step - loss: 0.2618 - acc: 0.8682 - val_loss: 0.3389 - val_acc: 0.8203\n",
      "Epoch 242/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2736 - acc: 0.8754 - val_loss: 0.3595 - val_acc: 0.8157\n",
      "Epoch 243/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2642 - acc: 0.8862 - val_loss: 0.3436 - val_acc: 0.8111\n",
      "Epoch 244/250\n",
      "39/38 [==============================] - 7s 182ms/step - loss: 0.2627 - acc: 0.8804 - val_loss: 0.3492 - val_acc: 0.8203\n",
      "Epoch 245/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2673 - acc: 0.8828 - val_loss: 0.3306 - val_acc: 0.8341\n",
      "Epoch 246/250\n",
      "39/38 [==============================] - 7s 178ms/step - loss: 0.2608 - acc: 0.8733 - val_loss: 0.3457 - val_acc: 0.8249\n",
      "Epoch 247/250\n",
      "39/38 [==============================] - 7s 181ms/step - loss: 0.2719 - acc: 0.8798 - val_loss: 0.3669 - val_acc: 0.8111\n",
      "Epoch 248/250\n",
      "39/38 [==============================] - 7s 179ms/step - loss: 0.2964 - acc: 0.8683 - val_loss: 0.3396 - val_acc: 0.8203\n",
      "Epoch 249/250\n",
      "39/38 [==============================] - 7s 180ms/step - loss: 0.2850 - acc: 0.8701 - val_loss: 0.3116 - val_acc: 0.8479\n",
      "Epoch 250/250\n",
      "39/38 [==============================] - 7s 177ms/step - loss: 0.2757 - acc: 0.8732 - val_loss: 0.3152 - val_acc: 0.8295\n",
      "Loading model\n",
      "Val/Train Loss: 0.239644689219/0.304388486158 Val/Train Acc: 0.894409937888/0.847926266732\n",
      "Training common network\n",
      "Epoch 1/30\n",
      "46/45 [==============================] - 18s 402ms/step - loss: 0.4323 - acc: 0.8203 - val_loss: 0.3407 - val_acc: 0.8447\n",
      "Epoch 2/30\n",
      "46/45 [==============================] - 15s 331ms/step - loss: 0.3052 - acc: 0.8746 - val_loss: 0.2977 - val_acc: 0.8882\n",
      "Epoch 3/30\n",
      "46/45 [==============================] - 15s 336ms/step - loss: 0.2732 - acc: 0.8767 - val_loss: 0.2741 - val_acc: 0.9130\n",
      "Epoch 4/30\n",
      "46/45 [==============================] - 15s 333ms/step - loss: 0.2579 - acc: 0.8848 - val_loss: 0.2925 - val_acc: 0.8944\n",
      "Epoch 5/30\n",
      "46/45 [==============================] - 15s 335ms/step - loss: 0.2674 - acc: 0.8869 - val_loss: 0.2811 - val_acc: 0.8944\n",
      "Epoch 6/30\n",
      "46/45 [==============================] - 16s 344ms/step - loss: 0.2491 - acc: 0.8892 - val_loss: 0.2765 - val_acc: 0.8944\n",
      "Epoch 7/30\n",
      "46/45 [==============================] - 16s 338ms/step - loss: 0.2607 - acc: 0.8903 - val_loss: 0.2594 - val_acc: 0.9130\n",
      "Epoch 8/30\n",
      "46/45 [==============================] - 16s 341ms/step - loss: 0.2622 - acc: 0.8923 - val_loss: 0.2466 - val_acc: 0.9255\n",
      "Epoch 9/30\n",
      "46/45 [==============================] - 15s 336ms/step - loss: 0.2473 - acc: 0.8882 - val_loss: 0.2338 - val_acc: 0.9255\n",
      "Epoch 10/30\n",
      "46/45 [==============================] - 16s 337ms/step - loss: 0.2511 - acc: 0.8862 - val_loss: 0.2514 - val_acc: 0.9130\n",
      "Epoch 11/30\n",
      "46/45 [==============================] - 15s 337ms/step - loss: 0.2497 - acc: 0.8964 - val_loss: 0.2433 - val_acc: 0.9193\n",
      "Epoch 12/30\n",
      "46/45 [==============================] - 15s 334ms/step - loss: 0.2664 - acc: 0.8875 - val_loss: 0.2422 - val_acc: 0.9193\n",
      "Epoch 13/30\n",
      "46/45 [==============================] - 16s 338ms/step - loss: 0.2467 - acc: 0.8930 - val_loss: 0.2391 - val_acc: 0.9193\n",
      "Epoch 14/30\n",
      "46/45 [==============================] - 15s 334ms/step - loss: 0.2440 - acc: 0.8903 - val_loss: 0.2565 - val_acc: 0.9130\n",
      "Epoch 15/30\n",
      "46/45 [==============================] - 15s 335ms/step - loss: 0.2421 - acc: 0.9062 - val_loss: 0.2452 - val_acc: 0.9006\n",
      "Epoch 16/30\n",
      "46/45 [==============================] - 15s 336ms/step - loss: 0.2390 - acc: 0.8953 - val_loss: 0.2329 - val_acc: 0.9255\n",
      "Epoch 17/30\n",
      "46/45 [==============================] - 15s 335ms/step - loss: 0.2340 - acc: 0.8998 - val_loss: 0.2370 - val_acc: 0.9130\n",
      "Epoch 18/30\n",
      "46/45 [==============================] - 15s 334ms/step - loss: 0.2435 - acc: 0.8971 - val_loss: 0.2828 - val_acc: 0.8820\n",
      "Epoch 19/30\n",
      "46/45 [==============================] - 15s 335ms/step - loss: 0.2309 - acc: 0.9035 - val_loss: 0.2611 - val_acc: 0.8944\n",
      "Epoch 20/30\n",
      "46/45 [==============================] - 16s 337ms/step - loss: 0.2358 - acc: 0.9059 - val_loss: 0.2390 - val_acc: 0.9006\n",
      "Epoch 21/30\n",
      "46/45 [==============================] - 16s 346ms/step - loss: 0.2342 - acc: 0.9082 - val_loss: 0.2183 - val_acc: 0.9193\n",
      "Epoch 22/30\n",
      "46/45 [==============================] - 16s 340ms/step - loss: 0.2277 - acc: 0.9008 - val_loss: 0.2364 - val_acc: 0.9006\n",
      "Epoch 23/30\n",
      "46/45 [==============================] - 15s 336ms/step - loss: 0.2215 - acc: 0.9018 - val_loss: 0.2754 - val_acc: 0.8882\n",
      "Epoch 24/30\n",
      "46/45 [==============================] - 16s 340ms/step - loss: 0.2512 - acc: 0.8909 - val_loss: 0.2388 - val_acc: 0.9006\n",
      "Epoch 25/30\n",
      "46/45 [==============================] - 16s 337ms/step - loss: 0.2336 - acc: 0.9035 - val_loss: 0.2460 - val_acc: 0.9068\n",
      "Epoch 26/30\n",
      "46/45 [==============================] - 16s 340ms/step - loss: 0.2530 - acc: 0.8998 - val_loss: 0.2312 - val_acc: 0.9130\n",
      "Epoch 27/30\n",
      "46/45 [==============================] - 16s 338ms/step - loss: 0.2388 - acc: 0.9059 - val_loss: 0.2171 - val_acc: 0.9068\n",
      "Epoch 28/30\n",
      "46/45 [==============================] - 16s 339ms/step - loss: 0.2299 - acc: 0.9049 - val_loss: 0.2168 - val_acc: 0.9068\n",
      "Epoch 29/30\n",
      "46/45 [==============================] - 16s 338ms/step - loss: 0.2351 - acc: 0.8947 - val_loss: 0.2167 - val_acc: 0.9130\n",
      "Epoch 30/30\n",
      "46/45 [==============================] - 15s 337ms/step - loss: 0.2267 - acc: 0.9150 - val_loss: 0.2189 - val_acc: 0.9068\n",
      "Loss: 0.216725381172 Acc: 0.913043478261\n"
     ]
    }
   ],
   "source": [
    "model_7 = train_models((y_train_7, X_b, X_images),\n",
    "                       lr = 8e-5,\n",
    "                       batch_size = 32,\n",
    "                       max_epoch = 250,\n",
    "                       verbose=1,\n",
    "                       return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test dataset\n",
      "Denoising and reshaping\n",
      "RGB done\n",
      "Predicting\n",
      "8424/8424 [==============================] - 37s 4ms/step\n",
      "Submitting\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if predict_submission:\n",
    "    print('Reading test dataset')\n",
    "    test_7 = pd.read_json(\"test.json\")\n",
    "    y_fin, X_fin_b, X_fin_img = create_dataset(test_7, False)\n",
    "    print('Predicting')\n",
    "    prediction_7 = model_7.predict([X_fin_b, X_fin_img], verbose=1, batch_size=32)\n",
    "    print('Submitting')\n",
    "    submission_7 = pd.DataFrame({'id': test_7[\"id\"], 'is_iceberg': prediction_7.reshape((prediction_7.shape[0]))})\n",
    "\n",
    "    submission_7.to_csv(\"model_7.csv\", index=False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### STACK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_model_1 = pd.read_csv(\"model_1.csv\", index_col=0)\n",
    "sub_model_2 = pd.read_csv(\"model_2.csv\", index_col=0)\n",
    "sub_model_3 = pd.read_csv(\"model_3.csv\", index_col=0)\n",
    "#sub_model_4 = pd.read_csv(\"model_4.csv\", index_col=0) #4b without 0.1430\n",
    "sub_model_5 = pd.read_csv(\"model_5.csv\", index_col=0)\n",
    "sub_model_6 = pd.read_csv(\"model_6.csv\", index_col=0)\n",
    "sub_model_7 = pd.read_csv(\"model_7.csv\", index_col=0) #4c with 0.1491\n",
    "\n",
    "concat_sub = pd.concat([sub_model_1,sub_model_2,sub_model_3,sub_model_5,sub_model_6,sub_model_7], axis=1)\n",
    "cols = list(map(lambda x: \"is_iceberg_\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_sub.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the data fields ready for stacking\n",
    "concat_sub['is_iceberg_max'] = concat_sub.iloc[:, 1:6].max(axis=1)\n",
    "concat_sub['is_iceberg_min'] = concat_sub.iloc[:, 1:6].min(axis=1)\n",
    "concat_sub['is_iceberg_mean'] = concat_sub.iloc[:, 1:6].mean(axis=1)\n",
    "concat_sub['is_iceberg_median'] = concat_sub.iloc[:, 1:6].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up cutoff threshold for lower and upper bounds, easy to twist \n",
    "cutoff_lo = 0.8\n",
    "cutoff_hi = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mean Stacking\n",
    "concat_sub['is_iceberg'] = concat_sub['is_iceberg_mean']\n",
    "concat_sub[['id', 'is_iceberg']].to_csv('stack_1.csv', \n",
    "                                        index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### STACK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Median Stacking\n",
    "concat_sub['is_iceberg'] = concat_sub['is_iceberg_median']\n",
    "concat_sub[['id', 'is_iceberg']].to_csv('stack_2.csv', \n",
    "                                        index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### STACK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Min max + Mean Stacking\n",
    "concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n",
    "                                    concat_sub['is_iceberg_max'], \n",
    "                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n",
    "                                             concat_sub['is_iceberg_min'], \n",
    "                                             concat_sub['is_iceberg_mean']))\n",
    "concat_sub[['id', 'is_iceberg']].to_csv('stack_3.csv', \n",
    "                                        index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### STACK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Min max + Median Stacking\n",
    "concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n",
    "                                    concat_sub['is_iceberg_max'], \n",
    "                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n",
    "                                             concat_sub['is_iceberg_min'], \n",
    "                                             concat_sub['is_iceberg_median']))\n",
    "concat_sub[['id', 'is_iceberg']].to_csv('stack_4c.csv', \n",
    "                                        index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### STACK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model with best base performance\n",
    "sub_base = pd.read_csv(\"model_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_sub['is_iceberg_base'] = sub_base['is_iceberg']\n",
    "concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n",
    "                                    concat_sub['is_iceberg_max'], \n",
    "                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n",
    "                                             concat_sub['is_iceberg_min'], \n",
    "                                             concat_sub['is_iceberg_base']))\n",
    "concat_sub[['id', 'is_iceberg']].to_csv('stack_5.csv', \n",
    "                                        index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
